{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14876f1-d7c7-45f1-85d6-616966a47e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/data/wangchen/instance_centric/instance_centric_model/')\n",
    "from parser_args import get_parser\n",
    "from src.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6551f38b-08a5-400b-b6b3-cc3643e95ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(batch_list):\n",
    "    batch_size = len(batch_list)\n",
    "    key_to_list = {}\n",
    "    for key in batch_list[0].keys():\n",
    "        key_to_list[key] = [batch_list[bs_idx][key] for bs_idx in range(batch_size)]\n",
    "\n",
    "    input_dict = {}\n",
    "    for key, val_list in key_to_list.items():\n",
    "        val_list = [torch.from_numpy(x) for x in val_list]\n",
    "        if key in ['agent_feats', 'agent_mask', 'agent_ctrs', 'agent_vecs', 'gt_preds',\n",
    "                    'plan_feat', 'plan_mask', 'map_ctrs', 'map_vecs', 'map_feats', 'map_mask']:\n",
    "            input_dict[key] = merge_batch_1d(val_list)\n",
    "        elif key in ['candidate_mask', 'gt_candts', 'rpe', 'rpe_mask']:\n",
    "            input_dict[key] = merge_batch_2d(val_list)\n",
    "        elif key in ['candidate_refpaths_cords', 'candidate_refpaths_vecs']:\n",
    "            input_dict[key] = merge_batch_2d_more(val_list)\n",
    "        else:\n",
    "            print(key)\n",
    "            continue\n",
    "    return input_dict\n",
    "\n",
    "def merge_batch_1d(tensor_list):\n",
    "    assert len(tensor_list[0].shape) in [2, 3]\n",
    "    only_2d_tensor = False\n",
    "    if len(tensor_list[0].shape) == 2:\n",
    "        tensor_list = [x.unsqueeze(dim=-1) for x in tensor_list]\n",
    "        only_2d_tensor = True\n",
    "    tensor_list = [x.unsqueeze(dim=0) for x in tensor_list]\n",
    "    max_feat0 = max([x.shape[1] for x in tensor_list])\n",
    "    _, _, num_feat1, num_feat2 = tensor_list[0].shape\n",
    "    ret_tensor_list = []\n",
    "    for k in range(len(tensor_list)):\n",
    "        cur_tensor = tensor_list[k]\n",
    "        assert cur_tensor.shape[2] == num_feat1 and cur_tensor.shape[3] == num_feat2\n",
    "\n",
    "        new_tensor = cur_tensor.new_zeros(cur_tensor.shape[0], max_feat0, num_feat1, num_feat2)\n",
    "        new_tensor[:, :cur_tensor.shape[1], :, :] = cur_tensor\n",
    "        ret_tensor_list.append(new_tensor)\n",
    "\n",
    "    ret_tensor = torch.cat(ret_tensor_list, dim=0)  # (num_stacked_samples, num_feat0_maxt, num_feat1, num_feat2)\n",
    "    if only_2d_tensor:\n",
    "        ret_tensor = ret_tensor.squeeze(dim=-1)\n",
    "    return ret_tensor\n",
    "\n",
    "def merge_batch_2d(tensor_list):\n",
    "    assert len(tensor_list[0].shape) in [2, 3]\n",
    "    only_2d_tensor = False\n",
    "    if len(tensor_list[0].shape) == 2:\n",
    "        tensor_list = [x.unsqueeze(dim=-1) for x in tensor_list]\n",
    "        only_2d_tensor = True\n",
    "    tensor_list = [x.unsqueeze(dim=0) for x in tensor_list]\n",
    "    max_feat0 = max([x.shape[1] for x in tensor_list])\n",
    "    max_feat1 = max([x.shape[2] for x in tensor_list])\n",
    "\n",
    "    num_feat2 = tensor_list[0].shape[-1]\n",
    "    ret_tensor_list = []\n",
    "    for k in range(len(tensor_list)):\n",
    "        cur_tensor = tensor_list[k]\n",
    "        new_tensor = cur_tensor.new_zeros(cur_tensor.shape[0], max_feat0, max_feat1, num_feat2)\n",
    "        new_tensor[:, :cur_tensor.shape[1], :cur_tensor.shape[2], :] = cur_tensor\n",
    "        ret_tensor_list.append(new_tensor)\n",
    "\n",
    "    ret_tensor = torch.cat(ret_tensor_list, dim=0)  # (num_stacked_samples, num_feat0_maxt, num_feat1_maxt, num_feat2)\n",
    "    if only_2d_tensor:\n",
    "        ret_tensor = ret_tensor.squeeze(dim=-1)\n",
    "    return ret_tensor\n",
    "\n",
    "def merge_batch_2d_more( tensor_list):\n",
    "    assert len(tensor_list[0].shape) == 4\n",
    "    tensor_list = [x.unsqueeze(dim=0) for x in tensor_list] # list[1, all_n, Max-N, 20, 2]\n",
    "    max_feat0 = max([x.shape[1] for x in tensor_list]) # all_n-Max\n",
    "    max_feat1 = max([x.shape[2] for x in tensor_list]) # Max-N-Max\n",
    "    num_feat2 = tensor_list[0].shape[3] # 20\n",
    "    num_feat3 = tensor_list[0].shape[4] # 2\n",
    "    ret_tensor_list = []\n",
    "\n",
    "    for k in range(len(tensor_list)):\n",
    "        cur_tensor = tensor_list[k]\n",
    "        new_tensor = cur_tensor.new_zeros(cur_tensor.shape[0], max_feat0, max_feat1, num_feat2, num_feat3) # 1, all_n-Max, Max-N-Max, 2\n",
    "        new_tensor[:, :cur_tensor.shape[1], :cur_tensor.shape[2], :, :] = cur_tensor\n",
    "        ret_tensor_list.append(new_tensor)\n",
    "\n",
    "    ret_tensor = torch.cat(ret_tensor_list, dim=0)  # bs,all_n-Max, Max-N-Max, 20, 2\n",
    "    return ret_tensor\n",
    "\n",
    "def transform_to_ori(feat, ctr, vec):\n",
    "    if not isinstance(feat, np.ndarray):\n",
    "        feat = feat.numpy()\n",
    "    if not isinstance(ctr, np.ndarray):\n",
    "        ctr = ctr.numpy()\n",
    "    cos_, sin_ = vec\n",
    "    rot = np.asarray([[sin_, cos_], [-cos_, sin_]])\n",
    "    rot_inv = rot.T\n",
    "    feat[:, 0:2] = np.matmul(feat[:, 0:2], rot_inv) + ctr\n",
    "    return feat\n",
    "\n",
    "def calculate_box_corners(x, y, yaw, length, width):\n",
    "    x += length*0.295*math.cos(yaw)\n",
    "    y += length*0.295*math.sin(yaw)\n",
    "    half_length = length/2\n",
    "    half_width = width/2\n",
    "    corner_xs, corner_ys = [], []\n",
    "    # right head\n",
    "    corner_xs.append(x + half_length * math.cos(yaw) + half_width * math.cos(yaw - 0.5*math.pi))\n",
    "    corner_ys.append(y + half_length * math.sin(yaw) + half_width * math.sin(yaw - 0.5*math.pi))\n",
    "    # left head\n",
    "    corner_xs.append(x + half_length * math.cos(yaw) + half_width * math.cos(yaw + 0.5*math.pi))\n",
    "    corner_ys.append(y + half_length * math.sin(yaw) + half_width * math.sin(yaw + 0.5*math.pi))\n",
    "    # left tail\n",
    "    corner_xs.append(x + half_length * math.cos(yaw + math.pi) + half_width * math.cos(yaw + 0.5*math.pi))\n",
    "    corner_ys.append(y + half_length * math.sin(yaw + math.pi) + half_width * math.sin(yaw + 0.5*math.pi))\n",
    "    # right tail\n",
    "    corner_xs.append(x + half_length * math.cos(yaw + math.pi) + half_width * math.cos(yaw - 0.5*math.pi))\n",
    "    corner_ys.append(y + half_length * math.sin(yaw + math.pi) + half_width * math.sin(yaw - 0.5*math.pi))\n",
    "\n",
    "    corner_xs.append(corner_xs[0])\n",
    "    corner_ys.append(corner_ys[0])\n",
    "    return corner_xs, corner_ys\n",
    "\n",
    "def select_top_n(ax, pred_trajs, pred_probs, top_n=1):\n",
    "    top_n = min(top_n, len(pred_probs))\n",
    "    max_scores_indices = pred_probs.argsort()[::-1][:top_n]\n",
    "    max_pred_trajs = pred_trajs[max_scores_indices,:, :]\n",
    "    scores = pred_probs[max_scores_indices]\n",
    "    score_sum = sum(scores)\n",
    "    acc_prob = 0\n",
    "    prob_info = ''\n",
    "    traj_index = 0\n",
    "    while traj_index < max_pred_trajs.shape[0]:\n",
    "        prob = scores[traj_index]\n",
    "        prob_info += f'{traj_index}:{str(round(prob/score_sum, 3))}, '\n",
    "        traj_index += 1\n",
    "        acc_prob += prob/score_sum\n",
    "        if acc_prob > 0.75:\n",
    "            break\n",
    "    return max_pred_trajs[:traj_index], prob_info\n",
    "\n",
    "def get_model_output(index):\n",
    "    pickle_path = input_dir + file_names[index]\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    input_dict = prepare_batch([data_dict]) \n",
    "    \n",
    "    print(\"==\"*100)\n",
    "    output_dict = model(input_dict)\n",
    "    return input_dict, output_dict\n",
    "\n",
    "def plot_case(input_dict, output_dict, save_path=None):\n",
    "    agent_feats = input_dict['agent_feats'][0]\n",
    "    agent_mask = input_dict['agent_mask'][0]\n",
    "    agent_ctrs = input_dict['agent_ctrs'][0]\n",
    "    agent_vecs = input_dict['agent_vecs'][0]\n",
    "    map_feats = input_dict['map_feats'][0]\n",
    "    map_mask = input_dict['map_mask'][0]\n",
    "    map_ctrs = input_dict['map_ctrs'][0]\n",
    "    map_vecs = input_dict['map_vecs'][0]\n",
    "    gt_preds = input_dict['gt_preds'][0]\n",
    "    pred_trajs = output_dict['trajs'][0].detach().cpu().numpy()\n",
    "    pred_probs = output_dict['traj_probs'][0].detach().cpu().numpy()\n",
    "    candiate_mask = input_dict['candidate_mask'][0]\n",
    "    pred_mask = candiate_mask.sum(dim=-1) > 0\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(22,12))\n",
    "    ax.axis(\"equal\")\n",
    "    min_width, min_height = 1e8, 1e8\n",
    "    max_width, max_height = -1, -1\n",
    "\n",
    "    # 画出周围地图信息\n",
    "    for i in range(map_feats.shape[0]):\n",
    "        line_info = transform_to_ori(map_feats[i][map_mask[i].bool()], map_ctrs[i], map_vecs[i])\n",
    "        ax.plot(line_info[:, 0], line_info[:, 1], color='y', linewidth=0.5)\n",
    "        min_width = min(min(line_info[:, 0]), min_width)\n",
    "        max_width = max(max(line_info[:, 0]), max_width)\n",
    "        min_height = min(min(line_info[:, 1]), min_height)\n",
    "        max_height = max(max(line_info[:, 1]), max_height)\n",
    "\n",
    "    # 障碍物信息\n",
    "    for i in range(pred_mask.shape[0]):\n",
    "        traj_info = transform_to_ori(agent_feats[i][agent_mask[i].bool()], agent_ctrs[i], agent_vecs[i])\n",
    "        min_width = min(min(traj_info[:, 0]), min_width)\n",
    "        max_width = max(max(traj_info[:, 0]), max_width)\n",
    "        min_height = min(min(traj_info[:, 1]), min_height)\n",
    "        max_height = max(max(traj_info[:, 1]), max_height)\n",
    "        ax.plot(traj_info[:, 0], traj_info[:, 1], color='tan', linewidth=2.0)\n",
    "        marker = '.'\n",
    "        color = 'g'\n",
    "        if pred_mask[i]:\n",
    "            # 目标障碍物\n",
    "            marker = '*'\n",
    "            color = 'b'\n",
    "            # 画出预测轨迹\n",
    "            top_trajs, prob_info = select_top_n(ax, pred_trajs[i], pred_probs[i], top_n=3)\n",
    "            ax.text(0.01, 0.95 - i*0.05, \"{}-traj_prob: {}\".format(i, prob_info), transform=ax.transAxes)\n",
    "            for j in range(top_trajs.shape[0]):\n",
    "                top_traj = transform_to_ori(top_trajs[j], agent_ctrs[i], agent_vecs[i])\n",
    "                pred_color = 'salmon'\n",
    "                if j == 0:\n",
    "                    pred_color = 'r'\n",
    "                ax.plot(top_traj[:, 0], top_traj[:, 1], color=pred_color, linewidth=2.0)\n",
    "            # 画出真实轨迹\n",
    "            gt_pred = transform_to_ori(gt_preds[i], agent_ctrs[i], agent_vecs[i])\n",
    "            ax.plot(gt_pred[:, 0], gt_pred[:, 1], color='b', linewidth=2.0)\n",
    "        elif i==0:\n",
    "            # ego\n",
    "            marker = '*'\n",
    "            color = 'r'\n",
    "        ax.plot(traj_info[-1, 0], traj_info[-1, 1], marker=marker, markersize=10, color=color) \n",
    "        length, width = traj_info[-1, 4], traj_info[-1, 5]\n",
    "        theta = math.atan2(agent_vecs[i][1], agent_vecs[i][0])\n",
    "        corner_xs, corner_ys = calculate_box_corners(traj_info[-1, 0], traj_info[-1, 1], theta, length, width)\n",
    "        ax.plot(corner_xs, corner_ys, color=color, linewidth=2.0)\n",
    "    roi_matrix = [min_width, max_width, min_height, max_height]\n",
    "    ax.axis(roi_matrix) \n",
    "    if save_path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path, dpi=250)\n",
    "        plt.close()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b9406b0-7019-4f60-ae85-d20720cf5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model_path = '/data/wangchen/instance_centric/instance_centric_model/output/MODEL/saved_models/MODEL_epoch_040.pt'\n",
    "parser = get_parser()\n",
    "args = parser.parse_args([])\n",
    "model = Model(args).cuda(0)\n",
    "device = torch.device('cuda:0')\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "input_dir = '/private/wangchen/instance_model_data/test/'\n",
    "file_names = os.listdir(input_dir)\n",
    "print(\"file num:\", len(file_names))\n",
    "output_dir = '/data/wangchen/plot_instance/'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29417edb-c4e1-432c-bf58-e8d1a05deabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "========================================================================================================================================================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking arugment for argument index in method wrapper_gather)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b84776484756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# for i in range(len(data['inter_info'])):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplot_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1e8d8bc1a8ed>\u001b[0m in \u001b[0;36mget_model_output\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rpe'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wangchen/instance_centric/instance_centric_model/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_dict)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mgt_refpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_candts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# [b, all_n-Max, Max-N-Max]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# target_probs, pred_targets, pred_offsets, param, param_with_gt, traj_probs = self.traj_decoder(agent_feats, candidate_refpaths_cords, candidate_refpaths_vecs, target_gt, candidate_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mcand_refpath_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_with_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraj_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_refpaths_cords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_refpaths_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_refpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;31m# 由贝塞尔控制点反推轨迹\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# bezier_param = torch.cat([param, pred_targets], dim=-1) # B, N, m, (n_order+1)*2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/wangchen/instance_centric/instance_centric_model/src/layers/traj_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feats, candidate_refpaths_cords, candidate_refpaths_vecs, gt_refpath, candidate_mask, batch_dict)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mgt_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# B, N, 1, (n_order+1)*2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mparam_with_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# B, N, 1, (n_order+1)*2 没做mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcand_refpath_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_with_gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking arugment for argument index in method wrapper_gather)"
     ]
    }
   ],
   "source": [
    "index = 103\n",
    "    # for i in range(len(data['inter_info'])):\n",
    "        \n",
    "    # for i in range(len(data['inter_info'])):\n",
    "        \n",
    "    # for i in range(len(data['inter_info'])):\n",
    "        \n",
    "    # for i in range(len(data['inter_info'])):\n",
    "    \n",
    "        \n",
    "    # for i in range(len(data['inter_info'])):\n",
    "        \n",
    "input_dict, output_dict = get_model_output(index)\n",
    "plot_case(input_dict, output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd50de46-0360-40b7-ac84-791cce6da39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_feats = input_dict['agent_feats'][0]\n",
    "agent_mask = input_dict['agent_mask'][0]\n",
    "agent_ctrs = input_dict['agent_ctrs'][0]\n",
    "agent_vecs = input_dict['agent_vecs'][0]\n",
    "map_feats = input_dict['map_feats'][0]\n",
    "map_mask = input_dict['map_mask'][0]\n",
    "map_ctrs = input_dict['map_ctrs'][0]\n",
    "map_vecs = input_dict['map_vecs'][0]\n",
    "gt_preds = input_dict['gt_preds'][0]\n",
    "pred_trajs = output_dict['trajs'][0].detach().cpu().numpy()\n",
    "pred_probs = output_dict['traj_probs'][0].detach().cpu().numpy()\n",
    "candiate_mask = input_dict['candidate_mask'][0]\n",
    "pred_mask = candiate_mask.sum(dim=-1) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e97318f-cd32-449f-85ee-2ad603e5c769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.3949, 5.4570, 5.4570, 5.4512, 5.4276, 5.4276, 5.3823, 5.3823, 4.1926,\n",
       "        5.1830, 5.1830, 5.1658, 5.1658, 5.0972, 5.0972, 5.0423, 5.0423, 4.9379,\n",
       "        4.9379, 4.8630])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_feats[1][:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f0ae6db-4bf8-494a-a7ce-a668464a28b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0695cdab-e4c5-4206-b510-dd11637d079c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d7b701-610f-452e-a9cb-9c6cbf066ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de139fb8-61d4-499c-a6ce-17c25b863974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b419954-7fc8-466d-8f5d-441044d186c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b37098-ed26-4ce7-be7c-9febe54e9b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84978e1-70a5-4a57-b602-498378c9feb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751dcf8-79ec-40b7-964d-738f3bdf8969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0e094-2676-4b83-b8da-8b614c73200d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af9196-f758-4fc9-94da-a3600c260598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d4b5f-40ca-4203-8c61-d203a24a4ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
