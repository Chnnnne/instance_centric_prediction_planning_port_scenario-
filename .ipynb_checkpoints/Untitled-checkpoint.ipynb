{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b98bf62-8702-4360-adad-2ded369a8cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "\n",
    "class SftLayer(nn.Module):\n",
    "    def __init__(self, d_edge, d_model, d_ffn, n_head = 8, dropout = 0.1, update_edge = True):\n",
    "        super().__init__()\n",
    "        self.update_edge = update_edge\n",
    "\n",
    "        self.proj_memory = nn.Sequential(\n",
    "            nn.Linear(d_model + d_model + d_edge, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        if self.update_edge:\n",
    "            self.proj_edge = nn.Sequential(\n",
    "                nn.Linear(d_model, d_edge),\n",
    "                nn.LayerNorm(d_edge),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            self.norm_edge = nn.LayerNorm(d_edge)\n",
    "\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, num_heads=n_head, dropout=dropout, batch_first=False)\n",
    "\n",
    "        # Feedforward model\n",
    "        self.linear1 = nn.Linear(d_model, d_ffn)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ffn, d_model)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, node, edge):\n",
    "        # update node\n",
    "        x, edge, memory = self._build_memory(node, edge)\n",
    "        x_prime, _ = self._mha_block(x, memory, attn_mask=None, key_padding_mask=None)\n",
    "        x = self.norm2(x + x_prime).squeeze()\n",
    "        x = self.norm3(x + self._ff_block(x))\n",
    "        return x, edge\n",
    "\n",
    "    def _build_memory(self, node, edge):\n",
    "        n_token = node.shape[0]\n",
    "\n",
    "        # 1. build memory\n",
    "        src_x = node.unsqueeze(dim=0).repeat([n_token, 1, 1])  # (N, N, d_model)\n",
    "        tar_x = node.unsqueeze(dim=1).repeat([1, n_token, 1])  # (N, N, d_model)\n",
    "        tmp = torch.cat([edge, src_x, tar_x], dim=-1)\n",
    "        memory = self.proj_memory(torch.cat([edge, src_x, tar_x], dim=-1))  # (N, N, d_model)\n",
    "        # 2. (optional) update edge (with residual)\n",
    "        if self.update_edge:\n",
    "            edge = self.norm_edge(edge + self.proj_edge(memory))  # (N, N, d_edge)\n",
    "\n",
    "        return node.unsqueeze(dim=0), edge, memory\n",
    "\n",
    "    # multihead attention block\n",
    "    def _mha_block(self, x, mem, attn_mask, key_padding_mask):\n",
    "        x, _ = self.multihead_attn(x, mem, mem,\n",
    "                                   attn_mask=attn_mask,\n",
    "                                   key_padding_mask=key_padding_mask,\n",
    "                                   need_weights=False)  # return average attention weights\n",
    "        return self.dropout2(x), None\n",
    "\n",
    "    # feed forward block\n",
    "    def _ff_block(self, x):\n",
    "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        return self.dropout3(x)\n",
    "\n",
    "\n",
    "\n",
    "class FusionNet(nn.Module):\n",
    "    def __init__(self, d_model, d_edge, n_head=8, n_layers=6, dropout=0.1, update_edge=True):\n",
    "        super().__init__()\n",
    "        fusion = []\n",
    "        for i in range(n_layers):\n",
    "            need_update_edge = False if i == n_layers - 1 else update_edge\n",
    "            fusion.append(SftLayer(d_edge=d_edge,\n",
    "                                   d_model=d_model,\n",
    "                                   d_ffn=d_model*2,\n",
    "                                   n_head=n_head,\n",
    "                                   dropout=dropout,\n",
    "                                   update_edge=need_update_edge))\n",
    "        self.fusion = nn.ModuleList(fusion)\n",
    "\n",
    "    def forward(self, agent_feats, agent_mask, map_feats, map_mask, rpe_feats, rpe_mask):\n",
    "        \"\"\"\n",
    "        agent_feats: batch_size, agent_num, dim\n",
    "        agent_mask: batch_size, agent_num\n",
    "        map_feats: batch_size, map_num, dim\n",
    "        map_mask: batch_size, map_num\n",
    "        rpe_feats: batch_size, N, N, dim_1\n",
    "        rpe_mask: batch_size, N, N\n",
    "        \"\"\"\n",
    "        x = torch.cat((agent_feats, map_feats), dim=1) \n",
    "        x_mask = torch.cat((agent_mask, map_mask), dim=1)\n",
    "        batch_size, all_num, dim = x.shape\n",
    "        agent_num = agent_feats.shape[1]\n",
    "        \n",
    "        agents_new, maps_new = list(), list()\n",
    "        for i in range(batch_size):\n",
    "            x_frame = x[i]\n",
    "            x_mask_frame = x_mask[i]\n",
    "            x_frame = x_frame[x_mask_frame].view(-1, dim) # (valid_num,dim)\n",
    "            valid_num = x_frame.shape[0]\n",
    "            rpe_frame = rpe_feats[i][rpe_mask[i]].view(valid_num, valid_num, -1)\n",
    "            for mod in self.fusion:\n",
    "                x_frame, rpe_frame= mod(x_frame, rpe_frame)\n",
    "            out = x_frame.new_zeros(all_num, x_frame.shape[-1])\n",
    "            out[x_mask_frame] = x_frame\n",
    "            agents_new.append(out[:agent_num])\n",
    "            maps_new.append(out[agent_num:])\n",
    "        agent_feats = torch.stack(agents_new)\n",
    "        map_feats = torch.stack(maps_new)\n",
    "        return agent_feats, map_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "948dab23-c796-45f7-99cb-264f97ddde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResMLP(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, hidden=64, bias=True, activation=\"relu\", norm='layer'):\n",
    "        super().__init__()\n",
    "\n",
    "        # define the activation function\n",
    "        if activation == \"relu\":\n",
    "            act_layer = nn.ReLU\n",
    "        elif activation == \"relu6\":\n",
    "            act_layer = nn.ReLU6\n",
    "        elif activation == \"leaky\":\n",
    "            act_layer = nn.LeakyReLU\n",
    "        elif activation == \"prelu\":\n",
    "            act_layer = nn.PReLU\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # define the normalization function\n",
    "        if norm == \"layer\":\n",
    "            norm_layer = nn.LayerNorm\n",
    "        elif norm == \"batch\":\n",
    "            norm_layer = nn.BatchNorm1d\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # insert the layers\n",
    "        self.linear1 = nn.Linear(in_channel, hidden, bias=bias)\n",
    "        self.linear2 = nn.Linear(hidden, out_channel, bias=bias)\n",
    "\n",
    "        self.norm1 = norm_layer(hidden)\n",
    "        self.norm2 = norm_layer(out_channel)\n",
    "\n",
    "        self.act1 = act_layer(inplace=True)\n",
    "        self.act2 = act_layer(inplace=True)\n",
    "\n",
    "        self.shortcut = None\n",
    "        if in_channel != out_channel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_channel, out_channel, bias=bias),\n",
    "                norm_layer(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.norm2(out)\n",
    "\n",
    "        if self.shortcut:\n",
    "            out += self.shortcut(x)\n",
    "        else:\n",
    "            out += x\n",
    "        return self.act2(out)\n",
    "\n",
    "\n",
    "class TrajDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_order=7, m=50):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.taregt_prob_layer = nn.Sequential(\n",
    "            ResMLP(input_size + 2, hidden_size, hidden_size),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        self.target_offset_layer = nn.Sequential(\n",
    "            ResMLP(input_size + 2, hidden_size, hidden_size),\n",
    "            nn.Linear(hidden_size, 2)\n",
    "        )\n",
    "        self.motion_estimator_layer = nn.Sequential(\n",
    "            ResMLP(input_size + 2, hidden_size, hidden_size),\n",
    "            nn.Linear(hidden_size, n_order*2)\n",
    "        )\n",
    "        \n",
    "        self.traj_prob_layer = nn.Sequential(\n",
    "            ResMLP(input_size + (n_order+1)*2, hidden_size, hidden_size),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Softmax(dim=2)\n",
    "        )\n",
    "    def forward(self, feats, tar_candidate, target_gt, candidate_mask=None):\n",
    "        \"\"\"\n",
    "        feats: B,N,D\n",
    "        tar_candidate: B, N, M, 2\n",
    "        target_gt:  B, N, 1, 2\n",
    "        candidate_mask: B, N, M\n",
    "        \"\"\"\n",
    "        \n",
    "        B, N, M, _ = tar_candidate.shape\n",
    "        feats_repeat = feats.unsqueeze(2).repeat(1, 1, M, 1)\n",
    "\n",
    "        # stack the target candidates to the end of input feature\n",
    "        feats_tar = torch.cat([feats_repeat, tar_candidate], dim=-1) # B, N, M, D+2\n",
    "        # compute probability for each candidate\n",
    "        prob_tensor = self.taregt_prob_layer(feats_tar).squeeze(-1) # B,N,M\n",
    "        target_probs = self.masked_softmax(prob_tensor, candidate_mask, dim=-1) # B, N, M\n",
    "        \n",
    "        tar_offsets = self.target_offset_layer(feats_tar) # B, N, M, 2\n",
    "        \n",
    "        m = min(target_probs.shape[2], self.m)\n",
    "        _, topk_indices = target_probs.topk(m, dim=2)\n",
    "        tar_indices = topk_indices.unsqueeze(-1).expand(topk_indices.shape[0], \n",
    "                                                        topk_indices.shape[1], \n",
    "                                                        topk_indices.shape[2], \n",
    "                                                        tar_candidate.shape[-1])\n",
    "        target_pred_se = torch.gather(tar_candidate, dim=2, index=tar_indices) # B, N, m, 2\n",
    "        offset_pred_se = torch.gather(tar_offsets, dim=2, index=tar_indices) # B, N, m, 2\n",
    "        \n",
    "        target_pred = target_pred_se + offset_pred_se\n",
    "        feat_indices = topk_indices.unsqueeze(-1).expand(topk_indices.shape[0], \n",
    "                                                        topk_indices.shape[1], \n",
    "                                                        topk_indices.shape[2], \n",
    "                                                        feats_repeat.shape[-1])\n",
    "        feats_traj = torch.gather(feats_repeat, dim=2, index=feat_indices) # B, N, m, D\n",
    "        feats_traj = torch.cat([feats_traj, target_pred], dim=-1) # B, N, m, D+2\n",
    "\n",
    "        param = self.motion_estimator_layer(feats_traj) # B,N,m,n_order*2\n",
    "        feats_traj = torch.cat([feats_traj, param], dim=-1)\n",
    "        traj_probs = self.traj_prob_layer(feats_traj).squeeze(-1) # B, N, m\n",
    "        \n",
    "        # 预测轨迹(teacher_force)\n",
    "        feat_traj_with_gt = torch.cat([feats.unsqueeze(2), target_gt], dim=-1) # B, N, 1, D+2\n",
    "        param_with_gt = self.motion_estimator_layer(feat_traj_with_gt) # B,N,1,n_order*2\n",
    "        \n",
    "        return target_probs, target_pred, tar_offsets, param, param_with_gt, traj_probs\n",
    "    \n",
    "    \n",
    "    def masked_softmax(self, vector, mask, dim=-1, memory_efficient=True, mask_fill_value=-1e32):\n",
    "        if mask is None:\n",
    "            result = F.softmax(vector, dim=dim)\n",
    "        else:\n",
    "            mask = mask.float()\n",
    "            while mask.dim() < vector.dim():\n",
    "                mask = mask.unsqueeze(-1)\n",
    "            if not memory_efficient:\n",
    "                # To limit numerical errors from large vector elements outside the mask, we zero these out.\n",
    "                result = F.softmax(vector * mask, dim=dim)\n",
    "                result = result * mask\n",
    "                result = result / (result.sum(dim=dim, keepdim=True) + 1e-13)\n",
    "                result = result.masked_fill((1 - mask).bool(), 0.0)\n",
    "            else:\n",
    "                masked_vector = vector.masked_fill((1 - mask).bool(), mask_fill_value)\n",
    "                result = F.softmax(masked_vector, dim=dim)\n",
    "                result = result.masked_fill((1 - mask).bool(), 0.0)\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "class PolylineNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size=None):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size, bias=True),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size, bias=True),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size*2, hidden_size, bias=True),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size, bias=True),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        if out_size is not None:\n",
    "            self.fc_out = nn.Sequential(\n",
    "                nn.Linear(hidden_size, hidden_size, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(hidden_size, out_size, bias=True)\n",
    "            )\n",
    "        else:\n",
    "            self.fc_out = None \n",
    "        \n",
    "\n",
    "    def forward(self, polylines, polylines_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            polylines (batch_size, num_polylines, num_points_each_polylines, C):\n",
    "            polylines_mask (batch_size, num_polylines, num_points_each_polylines):\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        bs, poly_num, point_num, C = polylines.shape\n",
    "        poly_feat_valid = self.fc1(polylines[polylines_mask])  # (N, C)\n",
    "        poly_feat = polylines.new_zeros(bs, poly_num, point_num, poly_feat_valid.shape[-1])\n",
    "        poly_feat[polylines_mask] = poly_feat_valid\n",
    "        \n",
    "        # get global feature\n",
    "        pooled_feat = poly_feat.max(dim=2)[0]\n",
    "        poly_feat = torch.cat((poly_feat, pooled_feat[:, :, None, :].repeat(1, 1, point_num, 1)), dim=-1)\n",
    "        # mlp\n",
    "        poly_feat_valid = self.fc2(poly_feat[polylines_mask])\n",
    "        feat_buffers = poly_feat.new_zeros(bs, poly_num, point_num, poly_feat_valid.shape[-1])\n",
    "        feat_buffers[polylines_mask] = poly_feat_valid\n",
    "        # max-pooling\n",
    "        feat_buffers = feat_buffers.max(dim=2)[0]  # (batch_size, num_polylines, C)\n",
    "        \n",
    "        # out-mlp \n",
    "        if self.fc_out is not None:\n",
    "            valid_mask = (polylines_mask.sum(dim=-1) > 0)\n",
    "            feat_buffers_valid = self.fc_out(feat_buffers[valid_mask])  # (N, C)\n",
    "            feat_buffers = feat_buffers.new_zeros(bs, poly_num, feat_buffers_valid.shape[-1])\n",
    "            feat_buffers[valid_mask] = feat_buffers_valid\n",
    "        return feat_buffers\n",
    "    \n",
    "class PlanNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.plan_mlp = PolylineNet(input_size, hidden_size)\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(hidden_size*2, 64),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Linear(64, 1), \n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, agent_feats, plan_traj, plan_traj_mask):\n",
    "        \"\"\"\n",
    "        plan_traj: B,N,d,2\n",
    "        plan_traj_mask: B,N,d\n",
    "        \"\"\"\n",
    "        batch_size, agent_num, _ = agent_feats.size() \n",
    "        ego_feat = agent_feats[:, 0].unsqueeze(1).expand(-1, agent_num, -1)\n",
    "        gate_feat = torch.cat((agent_feats, ego_feat), dim=-1)\n",
    "        gate = self.gate(gate_feat).squeeze(-1) # B*N\n",
    "        \n",
    "        if plan_traj.dim() == 3:\n",
    "            plan_traj = plan_traj.unsqueeze(1)\n",
    "            plan_traj_mask = plan_traj_mask.unsqueeze(1)\n",
    "        plan_feat = self.plan_mlp(plan_traj, plan_traj_mask).expand(-1, agent_num, -1) # B*N*D\n",
    "        plan_feat = torch.einsum('bnd,bn->bnd', plan_feat, gate)\n",
    "        agent_feats = agent_feats + plan_feat\n",
    "        return agent_feats, gate\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.device = self.args.device\n",
    "        self.agent_net = PolylineNet(  \n",
    "            input_size=self.args.agent_input_size,\n",
    "            hidden_size=self.args.agent_hidden_size,\n",
    "            out_size=self.args.d_model)\n",
    "        \n",
    "        self.map_net = PolylineNet(\n",
    "            input_size=self.args.map_input_size,\n",
    "            hidden_size=self.args.map_hidden_size,\n",
    "            out_size=self.args.d_model)\n",
    "        \n",
    "        self.rpe_net = nn.Sequential(\n",
    "            nn.Linear(self.args.rpe_input_size, self.args.rpe_hidden_size),\n",
    "            nn.LayerNorm(self.args.rpe_hidden_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.fusion_net = FusionNet(\n",
    "            d_model=self.args.d_model, \n",
    "            d_edge=self.args.rpe_hidden_size, \n",
    "            dropout=self.args.dropout,\n",
    "            update_edge=self.args.update_edge)\n",
    "        \n",
    "        self.plan_net = PlanNet(\n",
    "            input_size=self.args.plan_input_size, \n",
    "            hidden_size=self.args.d_model\n",
    "        )\n",
    "        \n",
    "        self.traj_decoder = TrajDecoder(\n",
    "            input_size=self.args.d_model,\n",
    "            hidden_size=self.args.decoder_hidden_size, \n",
    "            n_order=self.args.bezier_order, \n",
    "            m=self.args.m)\n",
    "        \n",
    "        self.mat_T = self._get_T_matrix_bezier(n_order=self.args.bezier_order, n_step=50).to(self.device)\n",
    "        \n",
    "        self.relation_decoder = None\n",
    "        if self.args.init_weights:\n",
    "            self.apply(self._init_weights)\n",
    "        \n",
    "    def forward(self, batch_dict):\n",
    "        agent_polylines, agent_polylines_mask = batch_dict['agent_polylines'], batch_dict['agent_polylines_mask'].bool() \n",
    "        map_polylines, map_polylines_mask = batch_dict['map_polylines'], batch_dict['map_polylines_mask'].bool() \n",
    "        agent_feats = self.agent_net(agent_polylines, agent_polylines_mask)\n",
    "        map_feats = self.map_net(map_polylines, map_polylines_mask)\n",
    "        \n",
    "        rpe, rpe_mask = batch_dict['rpe'], batch_dict['rpe_mask'].bool()\n",
    "        batch_size, N, _, _= rpe.shape\n",
    "        rpe_feats_valid = self.rpe_net(rpe[rpe_mask])  # (N, C)\n",
    "        rpe_feats = rpe_feats_valid.new_zeros(batch_size, N, N, rpe_feats_valid.shape[-1])\n",
    "        rpe_feats[rpe_mask] = rpe_feats_valid\n",
    "        \n",
    "        agent_mask = (agent_polylines_mask.sum(dim=-1) > 0)  \n",
    "        map_mask = (map_polylines_mask.sum(dim=-1) > 0)  \n",
    "        agent_feats, map_feat = self.fusion_net(agent_feats, agent_mask, map_feats, map_mask, rpe_feats, rpe_mask)\n",
    "        \n",
    "        plan_traj, plan_traj_mask = batch_dict['plan_traj'], batch_dict['plan_traj_mask']\n",
    "        agent_feats, gate = self.plan_net(agent_feats, plan_traj, plan_traj_mask)\n",
    "        \n",
    "        tar_candidate, candidate_mask = batch_dict['tar_candidate'], batch_dict['candidate_mask'].bool() \n",
    "        target_gt = batch_dict['gt_preds'][:, :, -1, :2]\n",
    "        target_gt = target_gt.view(target_gt.shape[0], target_gt.shape[1], 1, 2) # B, N, 1, 2\n",
    "        target_probs, pred_targets, pred_offsets, param, param_with_gt, traj_probs = self.traj_decoder(agent_feats, tar_candidate, target_gt, candidate_mask)\n",
    "           \n",
    "        # 由贝塞尔控制点反推轨迹\n",
    "        bezier_param = torch.cat([param, pred_targets], dim=-1) # B, N, m, (n_order+1)*2\n",
    "        bezier_control_points = bezier_param.view(bezier_param.shape[0],\n",
    "                                                  bezier_param.shape[1],\n",
    "                                                  bezier_param.shape[2], -1, 2) # B, N, m, n_order+1, 2\n",
    "        trajs = torch.matmul(self.mat_T, bezier_control_points) # B,N,m,future_steps,2\n",
    "        \n",
    "        bezier_param_with_gt = torch.cat([param_with_gt, target_gt], dim=-1) # B, N, 1, (n_order+1)*2\n",
    "        bezier_control_points_with_gt = bezier_param_with_gt.view(bezier_param_with_gt.shape[0],\n",
    "                                                          bezier_param_with_gt.shape[1],\n",
    "                                                          bezier_param_with_gt.shape[2], -1, 2) # B, N, 1, n_order+1, 2\n",
    "        traj_with_gt = torch.matmul(self.mat_T, bezier_control_points_with_gt) # B,N,1,future_steps,2\n",
    "\n",
    "        return {\"target_probs\": target_probs,\n",
    "                \"pred_offsets\": pred_offsets,\n",
    "                \"traj_with_gt\": traj_with_gt,\n",
    "                \"trajs\": trajs,\n",
    "                \"traj_probs\": traj_probs\n",
    "               }  \n",
    "        \n",
    "    def _get_T_matrix_bezier(self, n_order, n_step):\n",
    "        ts = np.linspace(0.0, 1.0, n_step, endpoint=True)\n",
    "        T = []\n",
    "        for i in range(n_order + 1):\n",
    "            coeff = math.factorial(n_order) // (math.factorial(i) * math.factorial(n_order - i)) * (1.0 - ts)**(n_order - i) * ts**i\n",
    "            # coeff = math.comb(n_order, i) * (1.0 - ts)**(n_order - i) * ts**i\n",
    "            T.append(coeff)\n",
    "        return torch.Tensor(np.array(T).T)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):\n",
    "            nn.init.ones_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.ones_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.MultiheadAttention):\n",
    "            if m.in_proj_weight is not None:\n",
    "                fan_in = m.embed_dim\n",
    "                fan_out = m.embed_dim\n",
    "                bound = (6.0 / (fan_in + fan_out)) ** 0.5\n",
    "                nn.init.uniform_(m.in_proj_weight, -bound, bound)\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(m.q_proj_weight)\n",
    "                nn.init.xavier_uniform_(m.k_proj_weight)\n",
    "                nn.init.xavier_uniform_(m.v_proj_weight)\n",
    "            if m.in_proj_bias is not None:\n",
    "                nn.init.zeros_(m.in_proj_bias)\n",
    "            nn.init.xavier_uniform_(m.out_proj.weight)\n",
    "            if m.out_proj.bias is not None:\n",
    "                nn.init.zeros_(m.out_proj.bias)\n",
    "            if m.bias_k is not None:\n",
    "                nn.init.normal_(m.bias_k, mean=0.0, std=0.02)\n",
    "            if m.bias_v is not None:\n",
    "                nn.init.normal_(m.bias_v, mean=0.0, std=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d044108b-9897-45a6-a170-eeef3075b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    \"\"\"Arguments for running the baseline.\n",
    "\n",
    "    Returns:\n",
    "        parsed arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--agent_input_size', default=4, type=int)\n",
    "    parser.add_argument('--agent_hidden_size', default=16, type=int)\n",
    "    parser.add_argument('--map_input_size', default=4, type=int)\n",
    "    parser.add_argument('--map_hidden_size', default=16, type=int)\n",
    "    parser.add_argument('--d_model', default=128, type=int)\n",
    "\n",
    "    parser.add_argument('--rpe_input_size', default=4, type=int)\n",
    "    parser.add_argument('--rpe_hidden_size', default=32, type=int)\n",
    "    parser.add_argument('--dropout', default=0.1, type=float)\n",
    "    \n",
    "    parser.add_argument('--plan_input_size', default=4, type=int)\n",
    "    parser.add_argument('--decoder_hidden_size', default=128, type=int)\n",
    "    parser.add_argument('--bezier_order', default=7, type=int)\n",
    "    parser.add_argument('--m', default=50, type=int)\n",
    "    \n",
    "    parser.add_argument('--device', default=\"cpu\", type=str) \n",
    "    parser.add_argument('--update_edge', default=True, type=bool)\n",
    "    parser.add_argument('--init_weights', default=True, type=bool)\n",
    "   \n",
    "    return parser.parse_args([])\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_arguments()\n",
    "    model = Model(args)\n",
    "    agent_feats = torch.randn([2, 2, 5, 4])\n",
    "    agent_mask =  torch.tensor([[[True,  True,  True, True, False],\n",
    "                     [ True,  True,  True, True, False]],\n",
    "                    [[True, True, False,  False, False],\n",
    "                     [False,  False,  False, False, False]]])\n",
    "    map_feats = torch.randn([2, 3, 5, 4])\n",
    "    map_mask =  torch.tensor([[[True,  True,  True, True, False],\n",
    "             [ True,  True,  True, True, False],\n",
    "             [False,  False,  False, False, False]],\n",
    "            [[True, True, False,  False, False],\n",
    "             [False,  False,  False, False, False],\n",
    "             [False,  False,  False, False, False]]])\n",
    "    rpe_feats = torch.randn([2, 5, 5, 4])\n",
    "    rpe_mask = torch.tensor([[[True,  True,  True, True, False],\n",
    "             [ True,  True,  True, True, False],\n",
    "             [ True,  True,  True, True, False],\n",
    "             [ True,  True,  True, True, False],\n",
    "             [False,  False,  False, False, False]],\n",
    "            [[True, True, False,  False, False],\n",
    "             [True, True, False,  False, False],\n",
    "             [False,  False,  False, False, False],\n",
    "             [False,  False,  False, False, False],\n",
    "             [False,  False,  False, False, False]]])\n",
    "    tar_candidate = torch.randn(2, 2, 300, 2)\n",
    "    candidate_mask = torch.randn(2, 2, 300)>0.5\n",
    "    gt_preds = torch.randn(2, 2, 50, 2)\n",
    "    \n",
    "    plan_traj = torch.randn(2, 2, 50, 4)\n",
    "    plan_traj_mask = torch.randn(2, 2, 50)>0.5\n",
    "    \n",
    "    gt_candts = torch.randn(2, 2, 300)\n",
    "    gt_tar_offset = torch.randn(2, 2, 2)\n",
    "    \n",
    "    batch_dict = {'agent_polylines':agent_feats, 'agent_polylines_mask':agent_mask,\n",
    "                  'map_polylines':map_feats, 'map_polylines_mask':map_mask, 'rpe':rpe_feats,\n",
    "                  'rpe_mask':rpe_mask, 'tar_candidate': tar_candidate, 'candidate_mask': candidate_mask, 'gt_preds':gt_preds,\n",
    "                  'plan_traj':plan_traj, 'plan_traj_mask':plan_traj_mask, 'gt_candts':gt_candts, 'gt_tar_offset':gt_tar_offset, \n",
    "                  'gt_preds':gt_preds\n",
    "                 }\n",
    "    output_dict = model(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f53f165d-7f3b-4d24-a466-0996920d294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Loss(nn.Module):\n",
    "    def __init__(self,):\n",
    "        \"\"\"\n",
    "        reduction: loss reduction, \"sum\" or \"mean\" (batch mean);\n",
    "        \"\"\"\n",
    "        super(Loss, self).__init__()\n",
    "        self.lambda1 = 1\n",
    "        self.lambda2 = 0.1\n",
    "        self.lambda3 = 1\n",
    "        self.lambda4 = 0.5\n",
    "\n",
    "        self.temper = 0.01\n",
    "        self.d_safe = 3.0\n",
    "    \n",
    "    def forward(self, batch_dict, output_dict, epoch=1):\n",
    "        loss = 0.0\n",
    "        pred_mask = (batch_dict['candidate_mask'].sum(dim=-1) > 0) # B, N    \n",
    "        # 1、target_loss\n",
    "        gt_probs = batch_dict['gt_candts'].float() # B, N, M \n",
    "\n",
    "        gt_probs = gt_probs[pred_mask] # S, M\n",
    "        pred_probs = output_dict['target_probs'][pred_mask]\n",
    "        pred_num = pred_probs.shape[0]\n",
    "        cls_loss = F.binary_cross_entropy(pred_probs, gt_probs, reduction='sum')/pred_num\n",
    "        \n",
    "        gt_tar_offset = batch_dict[\"gt_tar_offset\"] # B, N ,2\n",
    "        gt_tar_offset = gt_tar_offset[pred_mask] # S, 2\n",
    "        gt_idx = gt_probs.nonzero()[:pred_num] \n",
    "        print(gt_idx.shape)\n",
    "        pred_offsets = output_dict['pred_offsets'][pred_mask] # S, M, 2\n",
    "        pred_offsets = pred_offsets[gt_idx[:, 0], gt_idx[:, 1]] # S, 2\n",
    "        print(pred_offsets.shape)\n",
    "        offset_loss = F.smooth_l1_loss(pred_offsets, gt_tar_offset, reduction='sum')/pred_num\n",
    "        \n",
    "        # 2、motion reg loss\n",
    "        traj_with_gt = output_dict['traj_with_gt'].squeeze(2)[pred_mask] # S, 50, 2\n",
    "        gt_trajs = batch_dict['gt_preds'][pred_mask] # S, 50, 2\n",
    "        reg_loss = F.smooth_l1_loss(traj_with_gt, gt_trajs, reduction=\"sum\")/pred_num\n",
    "        \n",
    "        # 3、score_loss\n",
    "        pred_trajs = output_dict['trajs'][pred_mask] # S, m, 50, 2\n",
    "        S, m, horizon, dim = pred_trajs.shape\n",
    "        pred_trajs = pred_trajs.view(S, m , horizon*dim)\n",
    "        gt_trajs = gt_trajs.view(S, horizon*dim)\n",
    "        score_gt = F.softmax(-self.distance_metric(pred_trajs,  gt_trajs)/self.temper, dim=-1).detach()\n",
    "        score_loss = F.binary_cross_entropy(output_dict['traj_probs'][pred_mask], score_gt, reduction='sum')/pred_num\n",
    "\n",
    "        \n",
    "        if epoch > 10:\n",
    "            pred_trajs_t = pred_trajs.view(S, m, horizon, dim)\n",
    "            plan_traj = batch_dict[\"plan_traj\"][pred_mask][:, :, :2] # S, 50, 2\n",
    "            plan_traj_mask = batch_dict['plan_traj_mask'][pred_mask] # S, 50\n",
    "  \n",
    "            distances = torch.sqrt(torch.sum((pred_trajs_t - plan_traj.unsqueeze(1))**2, dim=-1)) # S, m, 50\n",
    "            masked_distances = distances.masked_fill(~plan_traj_mask.unsqueeze(1), 1000) # S, m, 50\n",
    "            min_distances = torch.min(masked_distances, dim=2)[0] # S, m\n",
    "\n",
    "            w_min_distances = output_dict['traj_probs'][pred_mask] * min_distances  # S, m\n",
    "            min_distances_sum = torch.sum(w_min_distances, dim=-1)\n",
    "            min_distances_sum = torch.clamp(min_distances_sum, max=self.d_safe)\n",
    "            safety_loss = -torch.mean(min_distances_sum)\n",
    "\n",
    "            loss = self.lambda1 * (cls_loss + offset_loss) + self.lambda2 * reg_loss + self.lambda3 * score_loss + self.lambda4 * safety_loss\n",
    "            loss_dict = {\"tar_cls_loss\": self.lambda1*cls_loss,\n",
    "                         \"tar_offset_loss\": self.lambda1*offset_loss,\n",
    "                         \"traj_loss\": self.lambda2*reg_loss,\n",
    "                         \"score_loss\": self.lambda3*score_loss,\n",
    "                         \"safety_loss\": self.lambda4 * safety_loss\n",
    "                        }\n",
    "        else:\n",
    "            loss = self.lambda1 * (cls_loss + offset_loss) + self.lambda2 * reg_loss + self.lambda3 * score_loss\n",
    "            loss_dict = {\"tar_cls_loss\": self.lambda1*cls_loss,\n",
    "                         \"tar_offset_loss\": self.lambda1*offset_loss,\n",
    "                         \"traj_loss\": self.lambda2*reg_loss,\n",
    "                         \"score_loss\": self.lambda3*score_loss}\n",
    "        return loss, loss_dict\n",
    "    \n",
    "     \n",
    "    def distance_metric(self, traj_candidate: torch.Tensor, traj_gt: torch.Tensor):\n",
    "        \"\"\"\n",
    "        compute the distance between the candidate trajectories and gt trajectory\n",
    "        :param traj_candidate: torch.Tensor, [batch_size, M, horizon * 2] or [M, horizon * 2]\n",
    "        :param traj_gt: torch.Tensor, [batch_size, horizon * 2] or [1, horizon * 2]\n",
    "        :return: distance, torch.Tensor, [batch_size, M] or [1, M]\n",
    "        \"\"\"\n",
    "        assert traj_gt.dim() == 2, \"Error dimension in ground truth trajectory\"\n",
    "        if traj_candidate.dim() == 3:\n",
    "            # batch case\n",
    "            pass\n",
    "\n",
    "        elif traj_candidate.dim() == 2:\n",
    "            traj_candidate = traj_candidate.unsqueeze(1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        assert traj_candidate.size()[2] == traj_gt.size()[1], \"Miss match in prediction horizon!\"\n",
    "\n",
    "        _, M, horizon_2_times = traj_candidate.size()\n",
    "        dis = torch.pow(traj_candidate - traj_gt.unsqueeze(1), 2).view(-1, M, int(horizon_2_times / 2), 2)\n",
    "\n",
    "        dis, _ = torch.max(torch.sum(dis, dim=3), dim=2)\n",
    "\n",
    "        return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "749bf064-08aa-4d02-b458-714ce167983f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "loss = Loss()\n",
    "loss, loss_dict = loss(batch_dict, output_dict, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659b2b88-d181-43ca-8d10-6da4cf0b44ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5b5b5cb-f0a9-4114-84c2-ef5a39e6f86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tar_cls_loss': tensor(-129.0979, grad_fn=<MulBackward0>),\n",
       " 'tar_offset_loss': tensor(1.0893, grad_fn=<MulBackward0>),\n",
       " 'traj_loss': tensor(5.4936, grad_fn=<MulBackward0>),\n",
       " 'score_loss': tensor(4.9789, grad_fn=<MulBackward0>),\n",
       " 'safety_loss': tensor(-0.1335, grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94178cd1-384e-43f1-8932-11462e78655f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4319893-122f-4533-a003-3b2fb8542f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c5708-d807-46bb-8863-faeb94e4c11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99f510-4ac4-43b9-a5c5-c83f6cd24675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28312ecc-3f1e-48a9-ad12-1989cf110ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd43cb-bedb-4e7f-b077-ce5b7c3b291a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dab609-6f7b-4c28-be7c-2e25de1ca3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06883c-e87f-4c84-bb91-f747f0676463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43273a6c-29a7-48f0-9bd5-dffcdd9b0a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be9b51-7716-4110-9c2f-69d6438e5757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e0677-3623-4055-bf08-ddd4b820cc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2ea83-6660-4007-b897-3a1f8f48b6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c2548b-3cb6-4f51-b028-82a45ef6804f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82be133-4843-4920-8a58-e5f441f8f09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09b975-905c-40c7-95ea-e2d06a40f1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847c491-7c91-4a11-a9b7-4d9d7b535846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504fa74-9f50-41e5-9b7a-27b4a7c90960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc416d4-3bff-434e-bbf2-c848ac5fc006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602b9d9-8b95-434a-9cfa-af1add58b68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c8a32-2506-4e3c-8902-bae8f57e0e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd51cf-64a0-4c34-8869-17f991ad60ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b233e-01e6-46b3-bee4-c0c8b19091ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c5227-c534-43da-af9b-1ed7219705eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c03ac-8ec7-4610-8942-328bfa6c08bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
