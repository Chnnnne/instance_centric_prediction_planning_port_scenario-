{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bedb477f-7b58-4267-9bfe-e894fc8bb73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from map_point_seacher import MapPointSeacher\n",
    "from modules.hdmap_lib.python.binding.libhdmap import HDMapManager, Vec2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b28b9200-6015-43ab-be5e-227a803a461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/private2/wanggang/pre_log_inter_data'\n",
    "all_file_list = [os.path.join(input_path, file) for file in os.listdir(input_path)][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9c3be9-aac0-415c-a661-75d5f301e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤掉无人化地图中横路上的部分数据(地图还没有做到）  \n",
    "def judge_undefined_scene(x, y):\n",
    "    a = -(80.0/77)\n",
    "    b = 3715155.25974\n",
    "    ans = y - a*x - b\n",
    "    return True if ans <= 0 else False\n",
    "    \n",
    "train_files, test_files = train_test_split(all_file_list, test_size=0.2, random_state=42)\n",
    "cur_files = train_files\n",
    "cur_output_path = '/private2/wanggang/instance_model_data/test'\n",
    "cur_output_path = Path(cur_output_path)\n",
    "if not cur_output_path.exists():\n",
    "    cur_output_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e02878-1e77-4d60-9712-7b3e8e0b0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = cur_files[0]\n",
    "with open(pickle_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "log_data = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b56b7a-f0fc-422c-8c3d-cc1260f5da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def parse_log_data(log_data):\n",
    "    data_info = {}\n",
    "    ego_id = -1\n",
    "    kDefaultCenterOffsetRatio = 0.401\n",
    "    kDefaultBaseOffsetRatio = 0.295\n",
    "    for i in range(len(log_data)):\n",
    "        cur_frame = log_data[i]\n",
    "        cur_t = cur_frame.timestamp\n",
    "        # 自车信息\n",
    "        if ego_id not in data_info:\n",
    "            data_info[ego_id] = {'t':[],'x':[], 'y':[], 'vel':[], 'vel_yaw':[], 'length':[], 'width':[], 'type':[]}\n",
    "        data_info[ego_id]['t'].append(cur_t)\n",
    "        data_info[ego_id]['x'].append(cur_frame.vehicle_state_debug.xy.x)\n",
    "        data_info[ego_id]['y'].append(cur_frame.vehicle_state_debug.xy.y)\n",
    "        data_info[ego_id]['vel'].append(cur_frame.vehicle_state_debug.vel)\n",
    "        data_info[ego_id]['vel_yaw'].append(cur_frame.vehicle_state_debug.yaw)\n",
    "        data_info[ego_id]['length'].append(6.855)\n",
    "        data_info[ego_id]['width'].append(2.996)\n",
    "        data_info[ego_id]['type'].append(-1)\n",
    "        # 障碍物信息\n",
    "        for agent in cur_frame.agent_map_debug.agents:\n",
    "            # planning 内部agent_type编码方式\n",
    "            # HUMAN = 0, CONTAINER_TRUCK = 1, TRUCK = 2, CAR = 3, BUS = 4, BICYCLE = 5, TRICYCLE = 6, CRANE = 7, GANTRY = 8,\n",
    "            # BLOCK = 9, RAILING = 10, STACKER = 11, UNKNOWN = 12, GRID = 13, CHARGER = 14\n",
    "            # container_truck和truck区分开\n",
    "            if agent.agent_type not in [0, 1, 2, 3, 4, 11]:\n",
    "                continue\n",
    "            agent_id = agent.agent_id.id\n",
    "            if agent_id not in data_info:\n",
    "                data_info[agent_id] = {'t':[],'x':[], 'y':[], 'vel':[], 'vel_yaw':[], 'length':[], 'width':[], 'type':[]}\n",
    "            if agent.HasField(\"connect_x\"):\n",
    "                x = agent.connect_x\n",
    "                y = agent.connect_y\n",
    "                vel = agent.head_vel\n",
    "                vel_yaw = agent.head_vel_yaw\n",
    "                pos_yaw = agent.head_yaw\n",
    "                length = agent.head_length\n",
    "                width = agent.head_width\n",
    "            elif agent.HasField(\"head_x\"):\n",
    "                # 基于挂车计算挂载点\n",
    "                offset = agent.length * kDefaultCenterOffsetRatio \n",
    "                x = agent.x + offset * math.cos(agent.yaw)\n",
    "                y = agent.y + offset * math.sin(agent.yaw)\n",
    "                vel = agent.head_vel\n",
    "                vel_yaw = agent.head_vel_yaw\n",
    "                pos_yaw = agent.head_yaw\n",
    "                length = agent.head_length\n",
    "                width = agent.head_width\n",
    "            else:\n",
    "                offset = 0.0 if agent.agent_type==0 else agent.length * kDefaultBaseOffsetRatio\n",
    "                x = agent.x - offset*math.cos(agent.yaw)\n",
    "                y = agent.y - offset*math.sin(agent.yaw)\n",
    "                vel = agent.vel\n",
    "                vel_yaw = agent.vel_yaw\n",
    "                pos_yaw = agent.yaw\n",
    "                length = agent.length\n",
    "                width = agent.width\n",
    "            if vel < 0.15:\n",
    "                vel_yaw = pos_yaw\n",
    "            data_info[agent_id]['t'].append(cur_t)\n",
    "            data_info[agent_id]['x'].append(x)\n",
    "            data_info[agent_id]['y'].append(y)\n",
    "            data_info[agent_id]['vel'].append(vel)\n",
    "            data_info[agent_id]['vel_yaw'].append(vel_yaw)\n",
    "            data_info[agent_id]['length'].append(length)\n",
    "            data_info[agent_id]['width'].append(width)\n",
    "            agent_type = agent.agent_type  \n",
    "            data_info[agent_id]['type'].append(agent_type)\n",
    "    return data_info\n",
    "\n",
    "cur_x, cur_y = log_data[0].vehicle_state_debug.xy.x, log_data[0].vehicle_state_debug.xy.y\n",
    "last_x, last_y = log_data[-1].vehicle_state_debug.xy.x, log_data[-1].vehicle_state_debug.xy.y\n",
    "# 过滤位于非有效地图上的数据\n",
    "if judge_undefined_scene(cur_x, cur_y) or judge_undefined_scene(last_x, last_y):\n",
    "    print(\"Undefined!\")\n",
    "    \n",
    "data_info = parse_log_data(log_data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57a1060c-f585-4b3a-819c-5f7a1615ba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_num: 166\n",
      "(3, 300, 2)\n",
      "(3, 300, 2)\n",
      "(2, 102, 2)\n",
      "(2, 50, 2)\n",
      "(2, 101, 2)\n",
      "(2, 50, 2)\n",
      "(2, 50, 2)\n",
      "None\n",
      "(1, 300, 2)\n",
      "(1, 300, 2)\n"
     ]
    }
   ],
   "source": [
    "def normalize_angle(angle):\n",
    "    PI = math.pi\n",
    "    return angle - 2*PI*np.floor((angle+PI)/(2*PI))   \n",
    "\n",
    "def get_valid_index(agent_info, valid_t):\n",
    "    index = -1\n",
    "    left, right = 0, len(agent_info['t'])-1\n",
    "    while left <= right:\n",
    "        mid = (left+right)>>1\n",
    "        if agent_info['t'][mid] > valid_t:\n",
    "            right = mid - 1\n",
    "        elif agent_info['t'][mid] < valid_t:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            index = mid\n",
    "            break\n",
    "    return index\n",
    "\n",
    "\n",
    "def get_agent_ids(data_info, cur_t):\n",
    "    surr_ids, target_ids = list(), list()\n",
    "    for id_, agent_info in data_info.items():\n",
    "        if id_ == -1:\n",
    "            continue\n",
    "        index = get_valid_index(agent_info, cur_t)\n",
    "        if index < 0:\n",
    "            continue\n",
    "        # 判断障碍物类型\n",
    "        if agent_info['type'][index] == 0 or agent_info['vel'][index] < 0.15: # 行人或者静止障碍物\n",
    "            surr_ids.append((id_, index))\n",
    "        else:\n",
    "            # 未来存在5s的真实轨迹\n",
    "            if len(agent_info['t']) - index <= 50 \\\n",
    "            or math.hypot(agent_info['x'][index]-agent_info['x'][index+50], agent_info['y'][index]-agent_info['y'][index+50]) < 5:\n",
    "                surr_ids.append((id_, index))\n",
    "            else:\n",
    "                target_ids.append((id_, index))\n",
    "    return surr_ids, target_ids\n",
    "\n",
    "def transform_to_local_coords(feat, center_xy, center_heading, heading_index=-1, type_index = -1):\n",
    "    theta = math.pi/2 - center_heading\n",
    "    rot = np.asarray([\n",
    "        [np.cos(theta), np.sin(theta)],\n",
    "        [-np.sin(theta), np.cos(theta)]])\n",
    "    feat[:, 0:2] = np.matmul((feat[:, 0:2] - center_xy), rot)\n",
    "\n",
    "     # 转化角度\n",
    "    if heading_index != -1:\n",
    "        for i in range(len(feat)):\n",
    "            feat[i, heading_index] = normalize_angle(feat[i, heading_index] - center_heading)\n",
    "\n",
    "    # 转化类别\n",
    "    if type_index != -1:\n",
    "        # TODO（wg）后续移除VEHICLE、BUS\n",
    "        #-1:ego, 0:'HUMAN', 1:CONTAINER_TRUCK, 2:TRUCK, 3:'CAR', 4:'BUS', 11:'STACKER'\n",
    "        types = [-1, 0, 1, 2, 3, 4, 11]\n",
    "        one_hot = np.eye(len(types))[np.searchsorted(types, feat[:, type_index])]\n",
    "        feat = np.concatenate((feat[:, :-1], one_hot), axis=-1)\n",
    "    return feat\n",
    "\n",
    "def get_candidate_gt(candidate_points, gt_target):\n",
    "    displacement = gt_target - candidate_points\n",
    "    gt_index = np.argmin(np.power(displacement[:, 0], 2) + np.power(displacement[:, 1], 2))\n",
    "\n",
    "    onehot = np.zeros(candidate_points.shape[0])\n",
    "    onehot[gt_index] = 1\n",
    "\n",
    "    offset_xy = gt_target - candidate_points[gt_index]\n",
    "    return onehot, offset_xy\n",
    "\n",
    "def pad_array_list(array_list):\n",
    "    '''\n",
    "    ayyay_list: 含有一系列二维矩阵，其中第一维的维度大小不一样\n",
    "    '''\n",
    "    # 找到最大的维度\n",
    "    max_dim = max(arr.shape[0] for arr in array_list)\n",
    "\n",
    "    # 填充数组为相同的维度并合并\n",
    "    padded_array_list = [np.concatenate([arr, np.zeros((max_dim - arr.shape[0],) + arr.shape[1:])]) for arr in array_list]\n",
    "    merged_array = np.stack(padded_array_list)\n",
    "    return merged_array\n",
    "\n",
    "def generate_future_feats(data_info: dict, target_ids: list):\n",
    "    n = len(target_ids)\n",
    "    tar_candidate, gt_preds, gt_candts, gt_tar_offset, candidate_mask = [], [], [], [], []\n",
    "    valid_flag = False\n",
    "    for i in range(n):\n",
    "        target_id, cur_index = target_ids[i]\n",
    "        agent_info = data_info[target_id]\n",
    "        center_xy = np.array([agent_info['x'][cur_index], agent_info['y'][cur_index]])\n",
    "        center_heading = agent_info['vel_yaw'][cur_index]\n",
    "        # 获取障碍物未来真实轨迹\n",
    "        agt_traj_fut = np.column_stack((agent_info['x'][cur_index+1:cur_index+51].copy(), agent_info['y'][cur_index+1:cur_index+51].copy())).astype(np.float32)\n",
    "        agt_traj_fut = transform_to_local_coords(agt_traj_fut, center_xy, center_heading)\n",
    "        # 采样目标点\n",
    "        ori = [agent_info['x'][cur_index], agent_info['y'][cur_index], \n",
    "               agent_info['vel'][cur_index], agent_info['vel_yaw'][cur_index], \n",
    "               agent_info['length'][cur_index], agent_info['width'][cur_index]]\n",
    "        candidate_points = mp_seacher.get_candidate_target_points(ori)\n",
    "        if len(candidate_points) == 0:\n",
    "            candidate_points = np.zeros((1, 2))\n",
    "            tar_candts_gt = np.zeros(1)\n",
    "            tar_offset_gt = np.zeros(2)\n",
    "            candts_mask = np.zeros((1))\n",
    "        else:    \n",
    "            candidate_points = np.asarray(candidate_points)\n",
    "            candidate_points = transform_to_local_coords(candidate_points, center_xy, center_heading)\n",
    "            tar_candts_gt, tar_offset_gt = get_candidate_gt(candidate_points, agt_traj_fut[-1, 0:2])\n",
    "            if math.hypot(tar_offset_gt[0], tar_offset_gt[1]) > 2:\n",
    "                candidate_points = np.zeros((1, 2))\n",
    "                tar_candts_gt = np.zeros(1)\n",
    "                tar_offset_gt = np.zeros(2)\n",
    "                candts_mask = np.zeros((1))\n",
    "            else:\n",
    "                candts_mask = np.ones((candidate_points.shape[0]))\n",
    "                valid_flag = True\n",
    "        \n",
    "        tar_candidate.append(candidate_points)\n",
    "        gt_preds.append(agt_traj_fut)\n",
    "        gt_candts.append(tar_candts_gt)\n",
    "        gt_tar_offset.append(tar_offset_gt)\n",
    "        candidate_mask.append(candts_mask)\n",
    "            \n",
    "    if not valid_flag:\n",
    "        return None, None, None, None, None\n",
    "    else:\n",
    "        tar_candidate = pad_array_list(tar_candidate) # N, M, 2\n",
    "        gt_preds = np.stack(gt_preds) # N, 50, 2\n",
    "        gt_tar_offset = np.stack(gt_tar_offset) # N, 2\n",
    "        gt_candts = pad_array_list(gt_candts)\n",
    "        candidate_mask = pad_array_list(candidate_mask)\n",
    "    return tar_candidate, gt_preds, gt_candts, gt_tar_offset, candidate_mask\n",
    "\n",
    "def generate_his_feats(data_info, agent_ids):\n",
    "    agent_feats, agent_masks = [], []\n",
    "    for agent_id, end_index in agent_ids:\n",
    "        agent_feat = np.zeros((20, 7))\n",
    "        agent_mask = np.zeros(20)\n",
    "        start_index = end_index - 19\n",
    "        index = 0\n",
    "        if start_index < 0:\n",
    "            start_index = 0\n",
    "            index = abs(start_index)\n",
    "        agent_info = data_info[agent_id]\n",
    "        while start_index <= end_index:\n",
    "            agent_feat[index] = np.array([agent_info['x'][start_index], agent_info['y'][start_index],\n",
    "                                          agent_info['vel'][start_index], agent_info['vel_yaw'][start_index],\n",
    "                                          agent_info['length'][start_index], agent_info['width'][start_index],\n",
    "                                          agent_info['type'][start_index]])\n",
    "            agent_mask[index] = 1\n",
    "            start_index += 1\n",
    "            index += 1\n",
    "        center_xy = np.array([agent_info['x'][end_index], agent_info['y'][end_index]])\n",
    "        center_heading = agent_info['vel_yaw'][end_index]\n",
    "        agent_feat = transform_to_local_coords(agent_feat, center_xy, center_heading, heading_index=3, type_index=6)\n",
    "        agent_feats.append(agent_feat)\n",
    "        agent_masks.append(agent_mask)\n",
    "    return np.stack(agent_feats), np.stack(agent_masks)\n",
    "\n",
    "def generate_plan_feats(data_info, target_ids, ego_index):\n",
    "    plan_traj = np.zeros((50, 4))\n",
    "    plan_traj_mask = np.zeros(50)\n",
    "    index = 0\n",
    "    ego_info = data_info[-1]\n",
    "    while index < 50:\n",
    "        plan_index = ego_index + index + 1\n",
    "        if plan_index >= len(ego_info['t']):\n",
    "            break\n",
    "        plan_traj[index] = np.array([ego_info['x'][plan_index], ego_info['y'][plan_index],\n",
    "                                      ego_info['vel'][plan_index], ego_info['vel_yaw'][plan_index]])\n",
    "        plan_traj_mask[index] = 1\n",
    "        index += 1\n",
    "    plan_feat, plan_mask = [], []\n",
    "    for agent_id, index in target_ids:\n",
    "        agent_info = data_info[agent_id]\n",
    "        center_xy = np.array([agent_info['x'][index], agent_info['y'][index]])\n",
    "        center_heading = agent_info['vel_yaw'][index]\n",
    "        plan_traj_ = transform_to_local_coords(plan_traj.copy(), center_xy, center_heading, heading_index=3)\n",
    "        plan_feat.append(plan_traj_)\n",
    "        plan_mask.append(plan_traj_mask.copy())\n",
    "    return np.stack(plan_feat), np.stack(plan_mask)\n",
    "\n",
    "def pad_array(array, target_shape):\n",
    "    padded_array = np.zeros(target_shape)\n",
    "    padded_array[1:1+array.shape[0]] = array\n",
    "    return padded_array\n",
    "\n",
    "def get_polyline_dir(polyline):\n",
    "    polyline_pre = np.roll(polyline, shift=1, axis=0)\n",
    "    polyline_pre[0] = polyline[0]\n",
    "    diff = polyline - polyline_pre\n",
    "    polyline_dir = diff / np.clip(np.linalg.norm(diff, axis=-1)[:, np.newaxis], a_min=1e-6, a_max=1000000000)\n",
    "    return polyline_dir\n",
    "\n",
    "def get_lane_infos(lanes, center_point, center_heading, distance=10, radius=100, num_points_each_polyline=20):\n",
    "    types_map = {\"junction\":0, \"lane\":1}\n",
    "    lane_polylines, lane_polylines_mask = [], []\n",
    "    lane_ctrs, lane_vecs = [], []\n",
    "    center_xy = np.array([center_point.x(), center_point.y()])\n",
    "    for lane in lanes:\n",
    "        if lane.IsInJunction():\n",
    "            continue\n",
    "        lane_s, _ = lane.GetProjection(center_point)\n",
    "        lane_heading = lane.GetHeading(lane_s)\n",
    "        if lane.bi_direction_lane():\n",
    "            diff_angle = normalize_angle(center_heading - lane_heading)\n",
    "            if abs(diff_angle) > math.pi/2:\n",
    "                continue\n",
    "        reference_line = lane.reference_line()\n",
    "        length = lane.length()\n",
    "        s = 0\n",
    "        count = 0\n",
    "        polyline = []\n",
    "        while s < length:\n",
    "            if count >= num_points_each_polyline:\n",
    "                break\n",
    "            point = reference_line.GetReferencePoint(s)\n",
    "            point = Vec2d(point.x(), point.y())\n",
    "            if (point - center_point).Length() < radius:\n",
    "                count += 1\n",
    "                polyline.append([point.x(), point.y(), types_map[\"lane\"]])\n",
    "            s += distance\n",
    "        if count == 0:\n",
    "            continue\n",
    "        polyline = np.asarray(polyline)\n",
    "        lane_ctr = np.mean(polyline[:, 0:2], axis=0)\n",
    "        lane_vec = [np.cos(lane_heading), np.sin(lane_heading)]\n",
    "        polyline = transform_to_local_coords(polyline, lane_ctr, lane_heading)\n",
    "        polyline_dir = get_polyline_dir(polyline[:, 0:2])\n",
    "        polyline = np.concatenate((polyline[:, 0:2], polyline_dir, polyline[:, 2:]), axis=-1)\n",
    "   \n",
    "        valid_num, point_dim =  min(num_points_each_polyline, polyline.shape[0]), polyline.shape[-1]\n",
    "        cur_polyline = np.zeros((num_points_each_polyline, point_dim))\n",
    "        cur_polyline_mask = np.zeros((num_points_each_polyline))\n",
    "        cur_polyline[:valid_num] = polyline[:valid_num]\n",
    "        cur_polyline_mask[:valid_num] = 1\n",
    "        lane_polylines.append(cur_polyline)\n",
    "        lane_polylines_mask.append(cur_polyline_mask)\n",
    "        lane_ctrs.append(lane_ctr)\n",
    "        lane_vecs.append(lane_vec)\n",
    "    if len(lane_polylines)==0:\n",
    "        return None, None, None, None\n",
    "    lane_polylines = np.stack(lane_polylines)\n",
    "    lane_polylines_mask = np.stack(lane_polylines_mask)\n",
    "    lane_ctrs = np.stack(lane_ctrs)\n",
    "    lane_vecs= np.stack(lane_vecs)\n",
    "    return lane_polylines, lane_polylines_mask, lane_ctrs, lane_vecs\n",
    "\n",
    "def get_junction_infos(junctions, distance=5.0, num_points_each_polyline=20):\n",
    "    types_map = {\"junction\":0, \"lane\":1}\n",
    "    junction_polylines, junction_polylines_mask = [], []\n",
    "    junction_ctrs, junction_vecs = [], []\n",
    "    for junction in junctions:\n",
    "        # 过滤船头船尾设置的虚拟路口\n",
    "        if junction.is_virtual_junction():\n",
    "            if \"vessel_head_and_tail\" in junction.attributes().attributes().values():\n",
    "                continue\n",
    "        points= junction.polygon().points()\n",
    "        points.append(points[0])\n",
    "        s = [0] + [math.hypot(points[i].x() - points[i-1].x(), points[i].y() - points[i-1].y()) for i in range(1, len(points))]\n",
    "        s = list(itertools.accumulate(s))\n",
    "\n",
    "        polyline = []\n",
    "        cur_length = 0\n",
    "        count = 0\n",
    "        while cur_length < s[-1]:\n",
    "            if count >= num_points_each_polyline:\n",
    "                break\n",
    "            s_idx = bisect.bisect_left(s, cur_length)\n",
    "            t = (cur_length - s[s_idx-1]) / (s[s_idx] - s[s_idx-1])\n",
    "            x = (1-t)*points[s_idx-1].x() + t*points[s_idx].x()\n",
    "            y = (1-t)*points[s_idx-1].y() + t*points[s_idx].y()\n",
    "            polyline.append([x, y, types_map[\"junction\"]])\n",
    "            cur_length += distance\n",
    "            count += 1\n",
    "        polyline = np.asarray(polyline)\n",
    "        junction_ctr = np.mean(polyline[:, 0:2], axis=0)\n",
    "        junction_vec = [np.cos(math.pi/2), np.sin(math.pi/2)]\n",
    "        polyline_dir = get_polyline_dir(polyline[:, 0:2])\n",
    "        polyline = transform_to_local_coords(polyline, junction_ctr, math.pi/2)\n",
    "        \n",
    "        polyline_dir = get_polyline_dir(polyline[:, 0:2])\n",
    "        polyline = np.concatenate((polyline[:, 0:2], polyline_dir, polyline[:, 2:]), axis=-1)\n",
    "\n",
    "        valid_num, point_dim = min(num_points_each_polyline, polyline.shape[0]), polyline.shape[-1]\n",
    "        cur_polyline = np.zeros((num_points_each_polyline, point_dim))\n",
    "        cur_polyline_mask = np.zeros((num_points_each_polyline))\n",
    "        cur_polyline[:valid_num] = polyline[:valid_num]\n",
    "        cur_polyline_mask[:valid_num] = 1\n",
    "        junction_polylines.append(cur_polyline)\n",
    "        junction_polylines_mask.append(cur_polyline_mask)\n",
    "        junction_ctrs.append(junction_ctr)\n",
    "        junction_vecs.append(junction_vec)\n",
    "    if len(junction_polylines)==0:\n",
    "        return None, None, None, None\n",
    "    junction_polylines = np.stack(junction_polylines)\n",
    "    junction_polylines_mask = np.stack(junction_polylines_mask)\n",
    "    junction_ctrs = np.stack(junction_ctrs)\n",
    "    junction_vecs = np.stack(junction_vecs)\n",
    "    return junction_polylines, junction_polylines_mask, junction_ctrs, junction_vecs\n",
    "    \n",
    "def generate_map_feats(ego_info, index, radius = 70):\n",
    "    center_point = Vec2d(ego_info[\"x\"][index], ego_info[\"y\"][index])\n",
    "    center_heading = ego_info[\"vel_yaw\"][index]\n",
    "    lanes = hdmap.GetLanes(center_point, radius)\n",
    "    junctions = hdmap.GetJunctions(center_point, radius)\n",
    "    lane_polylines, lane_polylines_mask, lane_ctrs, lane_vecs = get_lane_infos(lanes, center_point, center_heading)\n",
    "    \n",
    "    junction_polylines, junction_polylines_mask, junction_ctrs, junction_vecs = get_junction_infos(junctions)\n",
    "    if lane_polylines is None and junction_polylines is None:\n",
    "        return None, None, None, None\n",
    "    elif lane_polylines is None:\n",
    "        return junction_polylines, junction_polylines_mask, junction_ctrs, junction_vecs\n",
    "    elif junction_polylines is None:\n",
    "        return lane_polylines, lane_polylines_mask, lane_ctrs, lane_vecs\n",
    "    else:\n",
    "        map_polylines = np.concatenate((lane_polylines, junction_polylines), axis=0)\n",
    "        map_polylines_mask = np.concatenate((lane_polylines_mask, junction_polylines_mask), axis=0)\n",
    "        map_ctrs = np.concatenate((lane_ctrs, junction_ctrs), axis=0)\n",
    "        map_vecs = np.concatenate((lane_vecs, junction_vecs), axis=0)\n",
    "        return map_polylines, map_polylines_mask, map_ctrs, map_vecs\n",
    "\n",
    "def get_cos(v1, v2):\n",
    "    ''' 输入: [M, N, 2], [M, N, 2]\n",
    "        输出: [M, N]\n",
    "        cos(<a,b>) = (a·b) / |a||b|\n",
    "    '''\n",
    "    v1_norm = np.linalg.norm(v1, axis=-1)\n",
    "    v2_norm = np.linalg.norm(v2, axis=-1)\n",
    "    v1_x, v1_y = v1[..., 0], v1[..., 1]\n",
    "    v2_x, v2_y = v2[..., 0], v2[..., 1]\n",
    "    cos_dang = (v1_x * v2_x + v1_y * v2_y) / (v1_norm * v2_norm + 1e-10)\n",
    "    return cos_dang\n",
    "\n",
    "def get_sin(v1, v2):\n",
    "    ''' 输入: [M, N, 2], [M, N, 2]\n",
    "        输出: [M, N]\n",
    "        sin(<a,b>) = (a×b) / |a||b|\n",
    "    '''\n",
    "    v1_norm = np.linalg.norm(v1, axis=-1)\n",
    "    v2_norm = np.linalg.norm(v2, axis=-1)\n",
    "    v1_x, v1_y = v1[..., 0], v1[..., 1]\n",
    "    v2_x, v2_y = v2[..., 0], v2[..., 1]\n",
    "    sin_dang = (v1_x * v2_y - v1_y * v2_x) / (v1_norm * v2_norm + 1e-10)\n",
    "    return sin_dang\n",
    "    \n",
    "def generate_rpe_feats(ctrs, vecs):\n",
    "    d_pos = np.linalg.norm(ctrs[np.newaxis, :, :] - ctrs[:, np.newaxis, :], axis=-1)\n",
    "    d_pos = d_pos * 2 / 100  # scale [0, radius] to [0, 2]\n",
    "    pos_rpe = d_pos[np.newaxis, :]\n",
    "    cos_a1 = get_cos(vecs[np.newaxis, :], vecs[:, np.newaxis])\n",
    "    sin_a1 = get_sin(vecs[np.newaxis, :], vecs[:, np.newaxis])\n",
    "    v_pos = ctrs[np.newaxis, :, :] - ctrs[:, np.newaxis, :] \n",
    "    cos_a2 = get_cos(vecs[np.newaxis, :], v_pos)\n",
    "    sin_a2 = get_sin(vecs[np.newaxis, :], v_pos)\n",
    "\n",
    "    ang_rpe = np.stack([cos_a1, sin_a1, cos_a2, sin_a2])\n",
    "    rpe = np.concatenate([ang_rpe, pos_rpe], axis=0)\n",
    "    rpe = np.transpose(rpe, (1, 2, 0))\n",
    "    rpe_mask = np.ones((rpe.shape[0], rpe.shape[0]))\n",
    "    return rpe, rpe_mask\n",
    "\n",
    "if len(data_info) == 0 or -1 not in data_info:\n",
    "    print(\"data is empty!\")\n",
    "    \n",
    "map_file_path = \"/fabupilot/release/resources/hdmap_lib/meishangang/map.bin\"\n",
    "scene_type = 'port_meishan'\n",
    "HDMapManager.LoadMap(map_file_path, scene_type)\n",
    "hdmap = HDMapManager.GetHDMap()\n",
    "mp_seacher = MapPointSeacher(hdmap, t=5.0)\n",
    "ego_info = data_info[-1]\n",
    "frame_num = len(ego_info['t'])\n",
    "vehicle_name = pickle_path.split('/')[-1].split('_')[0]\n",
    "print(\"frame_num:\", frame_num)\n",
    "for i in range(19, frame_num-50, 10):\n",
    "    cur_t = ego_info['t'][i]\n",
    "    # 获取当前帧周围的障碍物和需要预测的障碍物id\n",
    "    surr_ids, target_ids = get_agent_ids(data_info, cur_t)\n",
    "    if len(target_ids) == 0:\n",
    "        continue\n",
    "    \n",
    "    # 计算目标障碍物的目标点等特征\n",
    "    tar_candidate, gt_preds, gt_candts, gt_tar_offset, candidate_mask = generate_future_feats(data_info, target_ids)\n",
    "    if tar_candidate is None:\n",
    "        print(\"None\")\n",
    "        continue\n",
    "    # 计算障碍物的历史特征\n",
    "    agent_ids = [(-1, i)]\n",
    "    agent_ids.extend(target_ids)\n",
    "    agent_ids.extend(surr_ids)\n",
    "    agent_feats, agent_masks = generate_his_feats(data_info, agent_ids)\n",
    "    agent_ctrs, agent_vecs = [], []\n",
    "    for agent_id, index in agent_ids:\n",
    "        agent_ctrs.append([data_info[agent_id]['x'][index], data_info[agent_id]['y'][index]])\n",
    "        theta = data_info[agent_id]['vel_yaw'][index]\n",
    "        agent_vecs.append([np.cos(theta), np.sin(theta)])\n",
    "    agent_ctrs = np.asarray(agent_ctrs)\n",
    "    agent_vecs = np.asarray(agent_vecs)\n",
    "    \n",
    "    # 计算plan特征\n",
    "    plan_feat, plan_mask = generate_plan_feats(data_info, target_ids, i)\n",
    "    \n",
    "    # pad\n",
    "    num = agent_feats.shape[0]\n",
    "    pad_tar_candidate = pad_array(tar_candidate, (num, tar_candidate.shape[1], tar_candidate.shape[2])) # N, M, 2\n",
    "    pad_gt_preds = pad_array(gt_preds, (num, gt_preds.shape[1], gt_preds.shape[2])) # N, 50, 2\n",
    "    pad_gt_candts = pad_array(gt_candts, (num, gt_candts.shape[1])) # N, M\n",
    "    pad_gt_tar_offset = pad_array(gt_tar_offset, (num, gt_tar_offset.shape[1])) # N, 2\n",
    "    pad_candidate_mask = pad_array(candidate_mask,(num, candidate_mask.shape[1])) # N, M\n",
    "    pad_plan_feat = pad_array(plan_feat, (num, plan_feat.shape[1], plan_feat.shape[2])) # N, 50, 4\n",
    "    pad_plan_mask = pad_array(plan_mask, (num, plan_mask.shape[1])) # N, 50\n",
    "    \n",
    "    # 计算地图特征\n",
    "    map_feats, map_mask, map_ctrs, map_vecs = generate_map_feats(data_info[-1], i, radius=80)\n",
    "    if map_feats is None:\n",
    "        continue\n",
    "        \n",
    "    # 计算rpe特征\n",
    "    scene_ctrs = np.concatenate((agent_ctrs, map_ctrs), axis=0)\n",
    "    scene_vecs = np.concatenate((agent_vecs, map_vecs), axis=0)\n",
    "    rpe, rpe_mask = generate_rpe_feats(scene_ctrs, scene_vecs)\n",
    "    \n",
    "    feat_data = {}\n",
    "    feat_data['agent_ctrs'] = agent_ctrs.astype(np.float32)\n",
    "    feat_data['agent_vecs'] = agent_vecs.astype(np.float32)\n",
    "    feat_data['agent_feats'] = agent_feats.astype(np.float32)\n",
    "    feat_data['agent_mask'] = agent_masks.astype(np.int32)\n",
    "    feat_data['tar_candidate'] = pad_tar_candidate.astype(np.float32)\n",
    "    feat_data['candidate_mask'] = pad_candidate_mask.astype(np.int32)\n",
    "    feat_data['gt_preds'] = pad_gt_preds.astype(np.float32)\n",
    "    feat_data['gt_candts'] = pad_gt_candts.astype(np.float32)\n",
    "    feat_data['gt_tar_offset'] = pad_gt_tar_offset.astype(np.float32)\n",
    "    feat_data['plan_feat'] = pad_plan_feat.astype(np.float32)\n",
    "    feat_data['plan_mask'] = pad_plan_mask.astype(np.int32)\n",
    "    feat_data['map_ctrs'] = map_ctrs.astype(np.float32)\n",
    "    feat_data['map_vecs'] = map_vecs.astype(np.float32)\n",
    "    feat_data['map_feats'] = map_feats.astype(np.float32)\n",
    "    feat_data['map_mask'] = map_mask.astype(np.int32)\n",
    "    feat_data['rpe'] = rpe.astype(np.float32)\n",
    "    feat_data['rpe_mask'] = rpe_mask.astype(np.int32)\n",
    "    save_path = str(cur_output_path) + f'/{vehicle_name}_{cur_t}.pkl'\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(feat_data, f)\n",
    "    print(tar_candidate.shape)\n",
    "    # break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80429ada-3af2-4865-95c0-e66591cd3ec9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-56d69b70e058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_candidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_candidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(tar_candidate[1][:, 0], tar_candidate[1][:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84896809-92f8-45c5-9841-8cac754a9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0.0, 1.0, 50, endpoint=True)\n",
    "n_order = 7\n",
    "T = []\n",
    "for i in range(n_order + 1):\n",
    "    coeff = math.factorial(n_order) // (math.factorial(i) * math.factorial(n_order - i)) * (1.0 - ts)**(n_order - i) * ts**i\n",
    "    # coeff = math.comb(n_order, i) * (1.0 - ts)**(n_order - i) * ts**i\n",
    "    T.append(coeff)\n",
    "T = np.array(T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d58c8c9-8beb-4632-b457-64dacfeb07e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88589a4-2344-4f80-85a2-d7ec675cbade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f36747-e867-4014-8428-1bf7a05ab74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d107f-41b6-4500-8864-b61c5024a129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e04f8-325e-463c-b4d7-eda2d3d6bf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85fa66c-7f0d-4b25-853f-e4acfda6c05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e11944-f003-46b9-8404-c3e12ae367b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774cdd2-4697-47a3-8c0d-a65f62572ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546cd14-70d6-4142-8eb1-eef7bf7a5ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd774b-5271-429b-a1c8-cdf01816bf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11802a2a-a583-4851-bc78-5d148a19ed39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
