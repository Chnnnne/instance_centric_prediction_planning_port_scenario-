{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c39d380-2f8c-41cd-925b-aba5709d722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bisect\n",
    "import itertools\n",
    "import math\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from map_point_seacher import MapPointSeacher\n",
    "from modules.hdmap_lib.python.binding.libhdmap import HDMapManager, Vec2d\n",
    "\n",
    "def judge_undefined_scene(x, y):\n",
    "    a = -(80.0/77)\n",
    "    b = 3715155.25974\n",
    "    ans = y - a*x - b\n",
    "    return True if ans <= 0 else False\n",
    "\n",
    "    \n",
    "def parse_log_data(log_data):\n",
    "    data_info = {}\n",
    "    ego_id = -1\n",
    "    kDefaultCenterOffsetRatio = 0.401\n",
    "    kDefaultBaseOffsetRatio = 0.295\n",
    "    for i in range(len(log_data)):\n",
    "        cur_frame = log_data[i]\n",
    "        cur_t = cur_frame.timestamp\n",
    "        # 自车信息\n",
    "        if ego_id not in data_info:\n",
    "            data_info[ego_id] = {'t':[],'x':[], 'y':[], 'vel':[], 'vel_yaw':[], 'length':[], 'width':[], 'type':[]}\n",
    "        data_info[ego_id]['t'].append(cur_t)\n",
    "        data_info[ego_id]['x'].append(cur_frame.vehicle_state_debug.xy.x)\n",
    "        data_info[ego_id]['y'].append(cur_frame.vehicle_state_debug.xy.y)\n",
    "        data_info[ego_id]['vel'].append(cur_frame.vehicle_state_debug.vel)\n",
    "        data_info[ego_id]['vel_yaw'].append(cur_frame.vehicle_state_debug.yaw)\n",
    "        data_info[ego_id]['length'].append(6.855)\n",
    "        data_info[ego_id]['width'].append(2.996)\n",
    "        data_info[ego_id]['type'].append(-1)\n",
    "        # 障碍物信息\n",
    "        for agent in cur_frame.agent_map_debug.agents:\n",
    "            # planning 内部agent_type编码方式\n",
    "            # HUMAN = 0, CONTAINER_TRUCK = 1, TRUCK = 2, CAR = 3, BUS = 4, BICYCLE = 5, TRICYCLE = 6, CRANE = 7, GANTRY = 8,\n",
    "            # BLOCK = 9, RAILING = 10, STACKER = 11, UNKNOWN = 12, GRID = 13, CHARGER = 14\n",
    "            # container_truck和truck区分开\n",
    "            if agent.agent_type not in [0, 1, 2, 3, 4, 11]:\n",
    "                continue\n",
    "            agent_id = agent.agent_id.id\n",
    "            if agent_id not in data_info:\n",
    "                data_info[agent_id] = {'t':[],'x':[], 'y':[], 'vel':[], 'vel_yaw':[], 'length':[], 'width':[], 'type':[]}\n",
    "            if agent.HasField(\"connect_x\"):\n",
    "                x = agent.connect_x\n",
    "                y = agent.connect_y\n",
    "                vel = agent.head_vel\n",
    "                vel_yaw = agent.head_vel_yaw\n",
    "                pos_yaw = agent.head_yaw\n",
    "                length = agent.head_length\n",
    "                width = agent.head_width\n",
    "            elif agent.HasField(\"head_x\"):\n",
    "                # 基于挂车计算挂载点\n",
    "                offset = agent.length * kDefaultCenterOffsetRatio \n",
    "                x = agent.x + offset * math.cos(agent.yaw)\n",
    "                y = agent.y + offset * math.sin(agent.yaw)\n",
    "                vel = agent.head_vel\n",
    "                vel_yaw = agent.head_vel_yaw\n",
    "                pos_yaw = agent.head_yaw\n",
    "                length = agent.head_length\n",
    "                width = agent.head_width\n",
    "            else:\n",
    "                offset = 0.0 if agent.agent_type==0 else agent.length * kDefaultBaseOffsetRatio\n",
    "                x = agent.x - offset*math.cos(agent.yaw)\n",
    "                y = agent.y - offset*math.sin(agent.yaw)\n",
    "                vel = agent.vel\n",
    "                vel_yaw = agent.vel_yaw\n",
    "                pos_yaw = agent.yaw\n",
    "                length = agent.length\n",
    "                width = agent.width\n",
    "            if vel < 0.15:\n",
    "                vel_yaw = pos_yaw\n",
    "            data_info[agent_id]['t'].append(cur_t)\n",
    "            data_info[agent_id]['x'].append(x)\n",
    "            data_info[agent_id]['y'].append(y)\n",
    "            data_info[agent_id]['vel'].append(vel)\n",
    "            data_info[agent_id]['vel_yaw'].append(vel_yaw)\n",
    "            data_info[agent_id]['length'].append(length)\n",
    "            data_info[agent_id]['width'].append(width)\n",
    "            agent_type = agent.agent_type  \n",
    "            data_info[agent_id]['type'].append(agent_type)\n",
    "    return data_info\n",
    "\n",
    "def normalize_angle(angle):\n",
    "    PI = math.pi\n",
    "    return angle - 2*PI*np.floor((angle+PI)/(2*PI))   \n",
    "\n",
    "def get_valid_index(agent_info, valid_t):\n",
    "    index = -1\n",
    "    left, right = 0, len(agent_info['t'])-1\n",
    "    while left <= right:\n",
    "        mid = (left+right)>>1\n",
    "        if agent_info['t'][mid] > valid_t:\n",
    "            right = mid - 1\n",
    "        elif agent_info['t'][mid] < valid_t:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            index = mid\n",
    "            break\n",
    "    return index\n",
    "\n",
    "\n",
    "def get_agent_ids(data_info, cur_t):\n",
    "    surr_ids, target_ids = list(), list()\n",
    "    for id_, agent_info in data_info.items():\n",
    "        if id_ == -1:\n",
    "            continue\n",
    "        index = get_valid_index(agent_info, cur_t)\n",
    "        if index < 0:\n",
    "            continue\n",
    "        # 判断障碍物类型\n",
    "        if agent_info['type'][index] == 0 or agent_info['vel'][index] < 0.15: # 行人或者静止障碍物\n",
    "            surr_ids.append((id_, index))\n",
    "        else:\n",
    "            # 未来存在5s的真实轨迹\n",
    "            if len(agent_info['t']) - index <= 50 \\\n",
    "            or math.hypot(agent_info['x'][index]-agent_info['x'][index+50], agent_info['y'][index]-agent_info['y'][index+50]) < 5:\n",
    "                surr_ids.append((id_, index))\n",
    "            else:\n",
    "                target_ids.append((id_, index))\n",
    "    return surr_ids, target_ids\n",
    "\n",
    "def transform_to_local_coords(feat, center_xy, center_heading, heading_index=-1, type_index = -1):\n",
    "    theta = math.pi/2 - center_heading\n",
    "    rot = np.asarray([\n",
    "        [np.cos(theta), np.sin(theta)],\n",
    "        [-np.sin(theta), np.cos(theta)]])\n",
    "    feat[:, 0:2] = np.matmul((feat[:, 0:2] - center_xy), rot)\n",
    "\n",
    "     # 转化角度\n",
    "    if heading_index != -1:\n",
    "        for i in range(len(feat)):\n",
    "            feat[i, heading_index] = normalize_angle(feat[i, heading_index] - center_heading)\n",
    "\n",
    "    # 转化类别\n",
    "    if type_index != -1:\n",
    "        # TODO（wg）后续移除VEHICLE、BUS\n",
    "        #-1:ego, 0:'HUMAN', 1:CONTAINER_TRUCK, 2:TRUCK, 3:'CAR', 4:'BUS', 11:'STACKER'\n",
    "        types = [-1, 0, 1, 2, 3, 4, 11]\n",
    "        one_hot = np.eye(len(types))[np.searchsorted(types, feat[:, type_index])]\n",
    "        feat = np.concatenate((feat[:, :-1], one_hot), axis=-1)\n",
    "    return feat\n",
    "\n",
    "def get_candidate_gt(candidate_points, gt_target):\n",
    "    displacement = gt_target - candidate_points\n",
    "    gt_index = np.argmin(np.power(displacement[:, 0], 2) + np.power(displacement[:, 1], 2))\n",
    "\n",
    "    onehot = np.zeros(candidate_points.shape[0])\n",
    "    onehot[gt_index] = 1\n",
    "\n",
    "    offset_xy = gt_target - candidate_points[gt_index]\n",
    "    return onehot, offset_xy\n",
    "\n",
    "def pad_array_list(array_list):\n",
    "    '''\n",
    "    ayyay_list: 含有一系列二维矩阵，其中第一维的维度大小不一样\n",
    "    '''\n",
    "    # 找到最大的维度\n",
    "    max_dim = max(arr.shape[0] for arr in array_list)\n",
    "\n",
    "    # 填充数组为相同的维度并合并\n",
    "    padded_array_list = [np.concatenate([arr, np.zeros((max_dim - arr.shape[0],) + arr.shape[1:])]) for arr in array_list]\n",
    "    merged_array = np.stack(padded_array_list)\n",
    "    return merged_array\n",
    "\n",
    "def generate_future_feats(data_info: dict, target_ids: list):\n",
    "    n = len(target_ids)\n",
    "    tar_candidate, gt_preds, gt_candts, gt_tar_offset, candidate_mask = [], [], [], [], []\n",
    "    valid_flag = False\n",
    "    for i in range(n):\n",
    "        target_id, cur_index = target_ids[i]\n",
    "        agent_info = data_info[target_id]\n",
    "        center_xy = np.array([agent_info['x'][cur_index], agent_info['y'][cur_index]])\n",
    "        center_heading = agent_info['vel_yaw'][cur_index]\n",
    "        # 获取障碍物未来真实轨迹\n",
    "        agt_traj_fut = np.column_stack((agent_info['x'][cur_index+1:cur_index+51].copy(), agent_info['y'][cur_index+1:cur_index+51].copy())).astype(np.float32)\n",
    "        agt_traj_fut = transform_to_local_coords(agt_traj_fut, center_xy, center_heading)\n",
    "        # 采样目标点\n",
    "        ori = [agent_info['x'][cur_index], agent_info['y'][cur_index], \n",
    "               agent_info['vel'][cur_index], agent_info['vel_yaw'][cur_index], \n",
    "               agent_info['length'][cur_index], agent_info['width'][cur_index]]\n",
    "        candidate_points = mp_seacher.get_candidate_target_points(ori)\n",
    "        if len(candidate_points) == 0:\n",
    "            candidate_points = np.zeros((1, 2))\n",
    "            tar_candts_gt = np.zeros(1)\n",
    "            tar_offset_gt = np.zeros(2)\n",
    "            candts_mask = np.zeros((1))\n",
    "        else:    \n",
    "            candidate_points = np.asarray(candidate_points)\n",
    "            candidate_points = transform_to_local_coords(candidate_points, center_xy, center_heading)\n",
    "            tar_candts_gt, tar_offset_gt = get_candidate_gt(candidate_points, agt_traj_fut[-1, 0:2])\n",
    "            if math.hypot(tar_offset_gt[0], tar_offset_gt[1]) > 2:\n",
    "                candidate_points = np.zeros((1, 2))\n",
    "                tar_candts_gt = np.zeros(1)\n",
    "                tar_offset_gt = np.zeros(2)\n",
    "                candts_mask = np.zeros((1))\n",
    "            else:\n",
    "                candts_mask = np.ones((candidate_points.shape[0]))\n",
    "                valid_flag = True\n",
    "        \n",
    "        tar_candidate.append(candidate_points)\n",
    "        gt_preds.append(agt_traj_fut)\n",
    "        gt_candts.append(tar_candts_gt)\n",
    "        gt_tar_offset.append(tar_offset_gt)\n",
    "        candidate_mask.append(candts_mask)\n",
    "            \n",
    "    if not valid_flag:\n",
    "        return None, None, None, None, None\n",
    "    else:\n",
    "        tar_candidate = pad_array_list(tar_candidate) # N, M, 2\n",
    "        gt_preds = np.stack(gt_preds) # N, 50, 2\n",
    "        gt_tar_offset = np.stack(gt_tar_offset) # N, 2\n",
    "        gt_candts = pad_array_list(gt_candts)\n",
    "        candidate_mask = pad_array_list(candidate_mask)\n",
    "    return tar_candidate, gt_preds, gt_candts, gt_tar_offset, candidate_mask\n",
    "\n",
    "def generate_his_feats(data_info, agent_ids):\n",
    "    agent_feats, agent_masks = [], []\n",
    "    for agent_id, end_index in agent_ids:\n",
    "        agent_feat = np.zeros((20, 7))\n",
    "        agent_mask = np.zeros(20)\n",
    "        start_index = end_index - 19\n",
    "        index = 0\n",
    "        if start_index < 0:\n",
    "            start_index = 0\n",
    "            index = abs(start_index)\n",
    "        agent_info = data_info[agent_id]\n",
    "        while start_index <= end_index:\n",
    "            agent_feat[index] = np.array([agent_info['x'][start_index], agent_info['y'][start_index],\n",
    "                                          agent_info['vel'][start_index], agent_info['vel_yaw'][start_index],\n",
    "                                          agent_info['length'][start_index], agent_info['width'][start_index],\n",
    "                                          agent_info['type'][start_index]])\n",
    "            agent_mask[index] = 1\n",
    "            start_index += 1\n",
    "            index += 1\n",
    "        center_xy = np.array([agent_info['x'][end_index], agent_info['y'][end_index]])\n",
    "        center_heading = agent_info['vel_yaw'][end_index]\n",
    "        agent_feat = transform_to_local_coords(agent_feat, center_xy, center_heading, heading_index=3, type_index=6)\n",
    "        agent_feats.append(agent_feat)\n",
    "        agent_masks.append(agent_mask)\n",
    "    return np.stack(agent_feats), np.stack(agent_masks)\n",
    "\n",
    "def generate_plan_feats(data_info, target_ids, ego_index):\n",
    "    plan_traj = np.zeros((50, 4))\n",
    "    plan_traj_mask = np.zeros(50)\n",
    "    index = 0\n",
    "    ego_info = data_info[-1]\n",
    "    while index < 50:\n",
    "        plan_index = ego_index + index + 1\n",
    "        if plan_index >= len(ego_info['t']):\n",
    "            break\n",
    "        plan_traj[index] = np.array([ego_info['x'][plan_index], ego_info['y'][plan_index],\n",
    "                                      ego_info['vel'][plan_index], ego_info['vel_yaw'][plan_index]])\n",
    "        plan_traj_mask[index] = 1\n",
    "        index += 1\n",
    "    plan_feat, plan_mask = [], []\n",
    "    for agent_id, index in target_ids:\n",
    "        agent_info = data_info[agent_id]\n",
    "        center_xy = np.array([agent_info['x'][index], agent_info['y'][index]])\n",
    "        center_heading = agent_info['vel_yaw'][index]\n",
    "        plan_traj_ = transform_to_local_coords(plan_traj.copy(), center_xy, center_heading, heading_index=3)\n",
    "        plan_feat.append(plan_traj_)\n",
    "        plan_mask.append(plan_traj_mask.copy())\n",
    "    return np.stack(plan_feat), np.stack(plan_mask)\n",
    "\n",
    "def pad_array(array, target_shape):\n",
    "    padded_array = np.zeros(target_shape)\n",
    "    padded_array[1:1+array.shape[0]] = array\n",
    "    return padded_array\n",
    "\n",
    "def get_polyline_dir(polyline):\n",
    "    polyline_pre = np.roll(polyline, shift=1, axis=0)\n",
    "    polyline_pre[0] = polyline[0]\n",
    "    diff = polyline - polyline_pre\n",
    "    polyline_dir = diff / np.clip(np.linalg.norm(diff, axis=-1)[:, np.newaxis], a_min=1e-6, a_max=1000000000)\n",
    "    return polyline_dir\n",
    "\n",
    "def get_lane_infos(lanes, center_point, center_heading, distance=10, radius=100, num_points_each_polyline=20):\n",
    "    types_map = {\"junction\":0, \"lane\":1}\n",
    "    lane_polylines, lane_polylines_mask = [], []\n",
    "    lane_ctrs, lane_vecs = [], []\n",
    "    center_xy = np.array([center_point.x(), center_point.y()])\n",
    "    for lane in lanes:\n",
    "        if lane.IsInJunction():\n",
    "            continue\n",
    "        lane_s, _ = lane.GetProjection(center_point)\n",
    "        lane_heading = lane.GetHeading(lane_s)\n",
    "        if lane.bi_direction_lane():\n",
    "            diff_angle = normalize_angle(center_heading - lane_heading)\n",
    "            if abs(diff_angle) > math.pi/2:\n",
    "                continue\n",
    "        reference_line = lane.reference_line()\n",
    "        length = lane.length()\n",
    "        s = 0\n",
    "        count = 0\n",
    "        polyline = []\n",
    "        while s < length:\n",
    "            if count >= num_points_each_polyline:\n",
    "                break\n",
    "            point = reference_line.GetReferencePoint(s)\n",
    "            point = Vec2d(point.x(), point.y())\n",
    "            if (point - center_point).Length() < radius:\n",
    "                count += 1\n",
    "                polyline.append([point.x(), point.y(), types_map[\"lane\"]])\n",
    "            s += distance\n",
    "        if count == 0:\n",
    "            continue\n",
    "        polyline = np.asarray(polyline)\n",
    "        lane_ctr = np.mean(polyline[:, 0:2], axis=0)\n",
    "        lane_vec = [np.cos(lane_heading), np.sin(lane_heading)]\n",
    "        polyline = transform_to_local_coords(polyline, lane_ctr, lane_heading)\n",
    "        polyline_dir = get_polyline_dir(polyline[:, 0:2])\n",
    "        polyline = np.concatenate((polyline[:, 0:2], polyline_dir, polyline[:, 2:]), axis=-1)\n",
    "   \n",
    "        valid_num, point_dim =  min(num_points_each_polyline, polyline.shape[0]), polyline.shape[-1]\n",
    "        cur_polyline = np.zeros((num_points_each_polyline, point_dim))\n",
    "        cur_polyline_mask = np.zeros((num_points_each_polyline))\n",
    "        cur_polyline[:valid_num] = polyline[:valid_num]\n",
    "        cur_polyline_mask[:valid_num] = 1\n",
    "        lane_polylines.append(cur_polyline)\n",
    "        lane_polylines_mask.append(cur_polyline_mask)\n",
    "        lane_ctrs.append(lane_ctr)\n",
    "        lane_vecs.append(lane_vec)\n",
    "    if len(lane_polylines)==0:\n",
    "        return None, None, None, None\n",
    "    lane_polylines = np.stack(lane_polylines)\n",
    "    lane_polylines_mask = np.stack(lane_polylines_mask)\n",
    "    lane_ctrs = np.stack(lane_ctrs)\n",
    "    lane_vecs= np.stack(lane_vecs)\n",
    "    return lane_polylines, lane_polylines_mask, lane_ctrs, lane_vecs\n",
    "\n",
    "def get_junction_infos(junctions, distance=5.0, num_points_each_polyline=20):\n",
    "    types_map = {\"junction\":0, \"lane\":1}\n",
    "    junction_polylines, junction_polylines_mask = [], []\n",
    "    junction_ctrs, junction_vecs = [], []\n",
    "    for junction in junctions:\n",
    "        # 过滤船头船尾设置的虚拟路口\n",
    "        if junction.is_virtual_junction():\n",
    "            if \"vessel_head_and_tail\" in junction.attributes().attributes().values():\n",
    "                continue\n",
    "        points= junction.polygon().points()\n",
    "        points.append(points[0])\n",
    "        s = [0] + [math.hypot(points[i].x() - points[i-1].x(), points[i].y() - points[i-1].y()) for i in range(1, len(points))]\n",
    "        s = list(itertools.accumulate(s))\n",
    "\n",
    "        polyline = []\n",
    "        cur_length = 0\n",
    "        count = 0\n",
    "        while cur_length < s[-1]:\n",
    "            if count >= num_points_each_polyline:\n",
    "                break\n",
    "            s_idx = bisect.bisect_left(s, cur_length)\n",
    "            t = (cur_length - s[s_idx-1]) / (s[s_idx] - s[s_idx-1])\n",
    "            x = (1-t)*points[s_idx-1].x() + t*points[s_idx].x()\n",
    "            y = (1-t)*points[s_idx-1].y() + t*points[s_idx].y()\n",
    "            polyline.append([x, y, types_map[\"junction\"]])\n",
    "            cur_length += distance\n",
    "            count += 1\n",
    "        polyline = np.asarray(polyline)\n",
    "        junction_ctr = np.mean(polyline[:, 0:2], axis=0)\n",
    "        junction_vec = [np.cos(math.pi/2), np.sin(math.pi/2)]\n",
    "        polyline_dir = get_polyline_dir(polyline[:, 0:2])\n",
    "        polyline = transform_to_local_coords(polyline, junction_ctr, math.pi/2)\n",
    "        \n",
    "        polyline_dir = get_polyline_dir(polyline[:, 0:2])\n",
    "        polyline = np.concatenate((polyline[:, 0:2], polyline_dir, polyline[:, 2:]), axis=-1)\n",
    "\n",
    "        valid_num, point_dim = min(num_points_each_polyline, polyline.shape[0]), polyline.shape[-1]\n",
    "        cur_polyline = np.zeros((num_points_each_polyline, point_dim))\n",
    "        cur_polyline_mask = np.zeros((num_points_each_polyline))\n",
    "        cur_polyline[:valid_num] = polyline[:valid_num]\n",
    "        cur_polyline_mask[:valid_num] = 1\n",
    "        junction_polylines.append(cur_polyline)\n",
    "        junction_polylines_mask.append(cur_polyline_mask)\n",
    "        junction_ctrs.append(junction_ctr)\n",
    "        junction_vecs.append(junction_vec)\n",
    "    if len(junction_polylines)==0:\n",
    "        return None, None, None, None\n",
    "    junction_polylines = np.stack(junction_polylines)\n",
    "    junction_polylines_mask = np.stack(junction_polylines_mask)\n",
    "    junction_ctrs = np.stack(junction_ctrs)\n",
    "    junction_vecs = np.stack(junction_vecs)\n",
    "    return junction_polylines, junction_polylines_mask, junction_ctrs, junction_vecs\n",
    "    \n",
    "def generate_map_feats(ego_info, index, radius = 70):\n",
    "    center_point = Vec2d(ego_info[\"x\"][index], ego_info[\"y\"][index])\n",
    "    center_heading = ego_info[\"vel_yaw\"][index]\n",
    "    lanes = hdmap.GetLanes(center_point, radius)\n",
    "    junctions = hdmap.GetJunctions(center_point, radius)\n",
    "    lane_polylines, lane_polylines_mask, lane_ctrs, lane_vecs = get_lane_infos(lanes, center_point, center_heading)\n",
    "    \n",
    "    junction_polylines, junction_polylines_mask, junction_ctrs, junction_vecs = get_junction_infos(junctions)\n",
    "    if lane_polylines is None and junction_polylines is None:\n",
    "        return None, None, None, None\n",
    "    elif lane_polylines is None:\n",
    "        return junction_polylines, junction_polylines_mask, junction_ctrs, junction_vecs\n",
    "    elif junction_polylines is None:\n",
    "        return lane_polylines, lane_polylines_mask, lane_ctrs, lane_vecs\n",
    "    else:\n",
    "        map_polylines = np.concatenate((lane_polylines, junction_polylines), axis=0)\n",
    "        map_polylines_mask = np.concatenate((lane_polylines_mask, junction_polylines_mask), axis=0)\n",
    "        map_ctrs = np.concatenate((lane_ctrs, junction_ctrs), axis=0)\n",
    "        map_vecs = np.concatenate((lane_vecs, junction_vecs), axis=0)\n",
    "        return map_polylines, map_polylines_mask, map_ctrs, map_vecs\n",
    "\n",
    "def get_cos(v1, v2):\n",
    "    ''' 输入: [M, N, 2], [M, N, 2]\n",
    "        输出: [M, N]\n",
    "        cos(<a,b>) = (a·b) / |a||b|\n",
    "    '''\n",
    "    v1_norm = np.linalg.norm(v1, axis=-1)\n",
    "    v2_norm = np.linalg.norm(v2, axis=-1)\n",
    "    v1_x, v1_y = v1[..., 0], v1[..., 1]\n",
    "    v2_x, v2_y = v2[..., 0], v2[..., 1]\n",
    "    cos_dang = (v1_x * v2_x + v1_y * v2_y) / (v1_norm * v2_norm + 1e-10)\n",
    "    return cos_dang\n",
    "\n",
    "def get_sin(v1, v2):\n",
    "    ''' 输入: [M, N, 2], [M, N, 2]\n",
    "        输出: [M, N]\n",
    "        sin(<a,b>) = (a×b) / |a||b|\n",
    "    '''\n",
    "    v1_norm = np.linalg.norm(v1, axis=-1)\n",
    "    v2_norm = np.linalg.norm(v2, axis=-1)\n",
    "    v1_x, v1_y = v1[..., 0], v1[..., 1]\n",
    "    v2_x, v2_y = v2[..., 0], v2[..., 1]\n",
    "    sin_dang = (v1_x * v2_y - v1_y * v2_x) / (v1_norm * v2_norm + 1e-10)\n",
    "    return sin_dang\n",
    "    \n",
    "def generate_rpe_feats(ctrs, vecs):\n",
    "    d_pos = np.linalg.norm(ctrs[np.newaxis, :, :] - ctrs[:, np.newaxis, :], axis=-1)\n",
    "    d_pos = d_pos * 2 / 100  # scale [0, radius] to [0, 2]\n",
    "    pos_rpe = d_pos[np.newaxis, :]\n",
    "    cos_a1 = get_cos(vecs[np.newaxis, :], vecs[:, np.newaxis])\n",
    "    sin_a1 = get_sin(vecs[np.newaxis, :], vecs[:, np.newaxis])\n",
    "    v_pos = ctrs[np.newaxis, :, :] - ctrs[:, np.newaxis, :] \n",
    "    cos_a2 = get_cos(vecs[np.newaxis, :], v_pos)\n",
    "    sin_a2 = get_sin(vecs[np.newaxis, :], v_pos)\n",
    "\n",
    "    ang_rpe = np.stack([cos_a1, sin_a1, cos_a2, sin_a2])\n",
    "    rpe = np.concatenate([ang_rpe, pos_rpe], axis=0)\n",
    "    rpe = np.transpose(rpe, (1, 2, 0))\n",
    "    rpe_mask = np.ones((rpe.shape[0], rpe.shape[0]))\n",
    "    return rpe, rpe_mask\n",
    "\n",
    "def load_seq_save_features(index):\n",
    "    pickle_path = cur_files[index]\n",
    "    with open(pickle_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    log_data = data['data']\n",
    "    \n",
    "    cur_x, cur_y = log_data[0].vehicle_state_debug.xy.x, log_data[0].vehicle_state_debug.xy.y\n",
    "    last_x, last_y = log_data[-1].vehicle_state_debug.xy.x, log_data[-1].vehicle_state_debug.xy.y\n",
    "    # 过滤位于非有效地图上的数据\n",
    "    if judge_undefined_scene(cur_x, cur_y) or judge_undefined_scene(last_x, last_y):\n",
    "        return\n",
    "    data_info = parse_log_data(log_data)\n",
    "    ego_info = data_info[-1]\n",
    "    frame_num = len(ego_info['t'])\n",
    "    vehicle_name = pickle_path.split('/')[-1].split('_')[0]\n",
    "    count = 0\n",
    "    for i in range(19, frame_num-50, 10):\n",
    "        cur_t = ego_info['t'][i]\n",
    "        # 获取当前帧周围的障碍物和需要预测的障碍物id\n",
    "        surr_ids, target_ids = get_agent_ids(data_info, cur_t)\n",
    "        if len(target_ids) == 0:\n",
    "            continue\n",
    "\n",
    "        # 计算目标障碍物的目标点等特征\n",
    "        tar_candidate, gt_preds, gt_candts, gt_tar_offset, candidate_mask = generate_future_feats(data_info, target_ids)\n",
    "        if tar_candidate is None:\n",
    "            continue\n",
    "        # 计算障碍物的历史特征\n",
    "        agent_ids = [(-1, i)]\n",
    "        agent_ids.extend(target_ids)\n",
    "        agent_ids.extend(surr_ids)\n",
    "        agent_feats, agent_masks = generate_his_feats(data_info, agent_ids)\n",
    "        agent_ctrs, agent_vecs = [], []\n",
    "        for agent_id, index in agent_ids:\n",
    "            agent_ctrs.append([data_info[agent_id]['x'][index], data_info[agent_id]['y'][index]])\n",
    "            theta = data_info[agent_id]['vel_yaw'][index]\n",
    "            agent_vecs.append([np.cos(theta), np.sin(theta)])\n",
    "        agent_ctrs = np.asarray(agent_ctrs)\n",
    "        agent_vecs = np.asarray(agent_vecs)\n",
    "\n",
    "        # 计算plan特征\n",
    "        plan_feat, plan_mask = generate_plan_feats(data_info, target_ids, i)\n",
    "\n",
    "        # pad\n",
    "        num = agent_feats.shape[0]\n",
    "        pad_tar_candidate = pad_array(tar_candidate, (num, tar_candidate.shape[1], tar_candidate.shape[2])) # N, M, 2\n",
    "        pad_gt_preds = pad_array(gt_preds, (num, gt_preds.shape[1], gt_preds.shape[2])) # N, 50, 2\n",
    "        pad_gt_candts = pad_array(gt_candts, (num, gt_candts.shape[1])) # N, M\n",
    "        pad_gt_tar_offset = pad_array(gt_tar_offset, (num, gt_tar_offset.shape[1])) # N, 2\n",
    "        pad_candidate_mask = pad_array(candidate_mask,(num, candidate_mask.shape[1])) # N, M\n",
    "        pad_plan_feat = pad_array(plan_feat, (num, plan_feat.shape[1], plan_feat.shape[2])) # N, 50, 4\n",
    "        pad_plan_mask = pad_array(plan_mask, (num, plan_mask.shape[1])) # N, 50\n",
    "\n",
    "        # 计算地图特征\n",
    "        map_feats, map_mask, map_ctrs, map_vecs = generate_map_feats(data_info[-1], i, radius=80)\n",
    "        if map_feats is None:\n",
    "            continue\n",
    "\n",
    "        # 计算rpe特征\n",
    "        scene_ctrs = np.concatenate((agent_ctrs, map_ctrs), axis=0)\n",
    "        scene_vecs = np.concatenate((agent_vecs, map_vecs), axis=0)\n",
    "        rpe, rpe_mask = generate_rpe_feats(scene_ctrs, scene_vecs)\n",
    "\n",
    "        feat_data = {}\n",
    "        feat_data['agent_ctrs'] = agent_ctrs.astype(np.float32)\n",
    "        feat_data['agent_vecs'] = agent_vecs.astype(np.float32)\n",
    "        feat_data['agent_feats'] = agent_feats.astype(np.float32)\n",
    "        feat_data['agent_mask'] = agent_masks.astype(np.int32)\n",
    "        feat_data['tar_candidate'] = pad_tar_candidate.astype(np.float32)\n",
    "        feat_data['candidate_mask'] = pad_candidate_mask.astype(np.int32)\n",
    "        feat_data['gt_preds'] = pad_gt_preds.astype(np.float32)\n",
    "        feat_data['gt_candts'] = pad_gt_candts.astype(np.float32)\n",
    "        feat_data['gt_tar_offset'] = pad_gt_tar_offset.astype(np.float32)\n",
    "        feat_data['plan_feat'] = pad_plan_feat.astype(np.float32)\n",
    "        feat_data['plan_mask'] = pad_plan_mask.astype(np.int32)\n",
    "        feat_data['map_ctrs'] = map_ctrs.astype(np.float32)\n",
    "        feat_data['map_vecs'] = map_vecs.astype(np.float32)\n",
    "        feat_data['map_feats'] = map_feats.astype(np.float32)\n",
    "        feat_data['map_mask'] = map_mask.astype(np.int32)\n",
    "        feat_data['rpe'] = rpe.astype(np.float32)\n",
    "        feat_data['rpe_mask'] = rpe_mask.astype(np.int32)\n",
    "        save_path = f'/{vehicle_name}_{cur_t}.pkl'\n",
    "        print(save_path)\n",
    "        count += 1\n",
    "    print(f\"总共生成了{count}个数据\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4068238-b440-430c-94f3-1180b622fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\": \n",
    "    map_file_path = \"/fabupilot/release/resources/hdmap_lib/meishangang/map.bin\"\n",
    "    scene_type = 'port_meishan'\n",
    "    HDMapManager.LoadMap(map_file_path, scene_type)\n",
    "    hdmap = HDMapManager.GetHDMap()\n",
    "    mp_seacher = MapPointSeacher(hdmap, t=5.0)\n",
    "    \n",
    "    input_path = '/private2/wanggang/pre_log_inter_data'\n",
    "    all_file_list = [os.path.join(input_path, file) for file in os.listdir(input_path)]\n",
    "    train_files, test_files = train_test_split(all_file_list, test_size=0.2, random_state=42)\n",
    "    cur_files = test_files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b082385c-21fd-4f42-b47f-9ffd42424354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private2/wanggang/pre_log_inter_data/howo60_1696431611.4768047.pkl\n",
      "/howo60_1696431613.3723502.pkl\n",
      "/howo60_1696431614.3714106.pkl\n",
      "/howo60_1696431615.3807003.pkl\n",
      "/howo60_1696431616.376291.pkl\n",
      "/howo60_1696431617.3731637.pkl\n",
      "/howo60_1696431618.2763011.pkl\n",
      "/howo60_1696431619.2718623.pkl\n",
      "/howo60_1696431620.2723265.pkl\n",
      "/howo60_1696431621.272066.pkl\n",
      "/howo60_1696431622.2750373.pkl\n",
      "/howo60_1696431623.2723098.pkl\n",
      "/howo60_1696431624.2723005.pkl\n",
      "/howo60_1696431625.2729583.pkl\n",
      "/howo60_1696431626.2730217.pkl\n",
      "/howo60_1696431627.2702835.pkl\n",
      "/howo60_1696431628.2718735.pkl\n",
      "/howo60_1696431629.279801.pkl\n",
      "/howo60_1696431630.2758381.pkl\n",
      "/howo60_1696431631.2802193.pkl\n",
      "/howo60_1696431632.2711112.pkl\n",
      "/howo60_1696431633.2728794.pkl\n",
      "/howo60_1696431634.2752695.pkl\n",
      "/howo60_1696431635.270923.pkl\n",
      "/howo60_1696431636.2766879.pkl\n",
      "/howo60_1696431637.2808235.pkl\n",
      "/howo60_1696431638.2757409.pkl\n",
      "/howo60_1696431639.271428.pkl\n",
      "/howo60_1696431640.270192.pkl\n",
      "/howo60_1696431641.270552.pkl\n",
      "/howo60_1696431642.2703867.pkl\n",
      "/howo60_1696431643.272069.pkl\n",
      "/howo60_1696431644.2816794.pkl\n",
      "/howo60_1696431645.27873.pkl\n",
      "/howo60_1696431646.2722144.pkl\n",
      "/howo60_1696431647.275847.pkl\n",
      "/howo60_1696431648.2725205.pkl\n",
      "/howo60_1696431649.2922645.pkl\n",
      "/howo60_1696431650.27295.pkl\n",
      "/howo60_1696431651.2755692.pkl\n",
      "/howo60_1696431652.27041.pkl\n",
      "/howo60_1696431653.2705498.pkl\n",
      "/howo60_1696431654.2703753.pkl\n",
      "/howo60_1696431655.2713654.pkl\n",
      "/howo60_1696431656.2707796.pkl\n",
      "/howo60_1696431657.2803442.pkl\n",
      "/howo60_1696431658.2815363.pkl\n",
      "/howo60_1696431659.272308.pkl\n",
      "/howo60_1696431660.2714927.pkl\n",
      "/howo60_1696431661.2779386.pkl\n",
      "/howo60_1696431662.2712903.pkl\n",
      "/howo60_1696431663.271114.pkl\n",
      "/howo60_1696431664.2702534.pkl\n",
      "/howo60_1696431665.2712574.pkl\n",
      "/howo60_1696431666.2703881.pkl\n",
      "/howo60_1696431667.2747436.pkl\n",
      "/howo60_1696431668.2702253.pkl\n",
      "/howo60_1696431669.2702036.pkl\n",
      "/howo60_1696431670.2722905.pkl\n",
      "/howo60_1696431671.2700748.pkl\n",
      "/howo60_1696431672.271511.pkl\n",
      "/howo60_1696431673.27692.pkl\n",
      "/howo60_1696431674.2781007.pkl\n",
      "/howo60_1696431675.2714505.pkl\n",
      "/howo60_1696431676.2704036.pkl\n",
      "/howo60_1696431677.278329.pkl\n",
      "/howo60_1696431678.2783113.pkl\n",
      "/howo60_1696431679.276354.pkl\n",
      "/howo60_1696431680.2724798.pkl\n",
      "/howo60_1696431681.2700279.pkl\n",
      "/howo60_1696431682.2805383.pkl\n",
      "/howo60_1696431683.273847.pkl\n",
      "/howo60_1696431684.2715034.pkl\n",
      "/howo60_1696431685.2710156.pkl\n",
      "/howo60_1696431686.2777162.pkl\n",
      "/howo60_1696431687.2711823.pkl\n",
      "/howo60_1696431688.2710965.pkl\n",
      "/howo60_1696431689.271282.pkl\n",
      "/howo60_1696431690.2803698.pkl\n",
      "/howo60_1696431691.2761352.pkl\n",
      "/howo60_1696431692.2708926.pkl\n",
      "/howo60_1696431693.2742965.pkl\n",
      "/howo60_1696431694.2708704.pkl\n",
      "/howo60_1696431695.2726777.pkl\n",
      "/howo60_1696431696.2698565.pkl\n",
      "/howo60_1696431697.271696.pkl\n",
      "/howo60_1696431698.2709732.pkl\n",
      "/howo60_1696431699.2767122.pkl\n",
      "/howo60_1696431700.2716875.pkl\n",
      "/howo60_1696431701.2702346.pkl\n",
      "/howo60_1696431702.272784.pkl\n",
      "/howo60_1696431703.27122.pkl\n",
      "/howo60_1696431704.270829.pkl\n",
      "/howo60_1696431705.2703717.pkl\n",
      "/howo60_1696431706.277295.pkl\n",
      "/howo60_1696431707.2707057.pkl\n",
      "/howo60_1696431708.27288.pkl\n",
      "/howo60_1696431709.2707212.pkl\n",
      "/howo60_1696431710.2698638.pkl\n",
      "/howo60_1696431711.2706985.pkl\n",
      "/howo60_1696431712.2750561.pkl\n",
      "/howo60_1696431713.2770112.pkl\n",
      "/howo60_1696431714.2731023.pkl\n",
      "/howo60_1696431715.2789903.pkl\n",
      "/howo60_1696431716.272975.pkl\n",
      "/howo60_1696431717.2789564.pkl\n",
      "/howo60_1696431718.2801368.pkl\n",
      "/howo60_1696431719.271025.pkl\n",
      "/howo60_1696431720.2702112.pkl\n",
      "/howo60_1696431721.2808223.pkl\n",
      "/howo60_1696431722.2728148.pkl\n",
      "/howo60_1696431723.2707024.pkl\n",
      "/howo60_1696431724.2706423.pkl\n",
      "/howo60_1696431725.27262.pkl\n",
      "/howo60_1696431726.269624.pkl\n",
      "/howo60_1696431727.2822134.pkl\n",
      "/howo60_1696431728.270638.pkl\n",
      "/howo60_1696431729.2711267.pkl\n",
      "/howo60_1696431730.2833092.pkl\n",
      "/howo60_1696431731.2715976.pkl\n",
      "/howo60_1696431732.2698152.pkl\n",
      "/howo60_1696431733.2772138.pkl\n",
      "/howo60_1696431734.27305.pkl\n",
      "/howo60_1696431735.2720869.pkl\n",
      "/howo60_1696431736.2809768.pkl\n",
      "/howo60_1696431737.2702498.pkl\n",
      "/howo60_1696431738.2705681.pkl\n",
      "/howo60_1696431739.273046.pkl\n",
      "/howo60_1696431740.275891.pkl\n",
      "/howo60_1696431741.2727973.pkl\n",
      "/howo60_1696431742.275769.pkl\n",
      "/howo60_1696431743.272201.pkl\n",
      "/howo60_1696431744.2705567.pkl\n",
      "/howo60_1696431745.2705476.pkl\n",
      "/howo60_1696431746.272029.pkl\n",
      "/howo60_1696431747.27828.pkl\n",
      "/howo60_1696431748.2705786.pkl\n",
      "/howo60_1696431749.270103.pkl\n",
      "/howo60_1696431750.2786722.pkl\n",
      "/howo60_1696431751.2736564.pkl\n",
      "/howo60_1696431752.270543.pkl\n",
      "/howo60_1696431753.2722025.pkl\n",
      "/howo60_1696431754.2703.pkl\n",
      "/howo60_1696431755.2715592.pkl\n",
      "/howo60_1696431756.277924.pkl\n",
      "/howo60_1696431757.275243.pkl\n",
      "/howo60_1696431758.2799907.pkl\n",
      "/howo60_1696431759.2715971.pkl\n",
      "/howo60_1696431760.2746575.pkl\n",
      "/howo60_1696431761.270811.pkl\n",
      "/howo60_1696431762.2795744.pkl\n",
      "/howo60_1696431763.271472.pkl\n",
      "/howo60_1696431764.279491.pkl\n",
      "/howo60_1696431765.2707388.pkl\n",
      "/howo60_1696431766.2845376.pkl\n",
      "/howo60_1696431767.2741952.pkl\n",
      "/howo60_1696431768.278435.pkl\n",
      "/howo60_1696431769.2730675.pkl\n",
      "/howo60_1696431770.2787235.pkl\n",
      "/howo60_1696431771.2695494.pkl\n",
      "/howo60_1696431772.2704604.pkl\n",
      "/howo60_1696431773.2741241.pkl\n",
      "/howo60_1696431774.2735066.pkl\n",
      "/howo60_1696431775.2784417.pkl\n",
      "/howo60_1696431776.2776961.pkl\n",
      "/howo60_1696431777.2807195.pkl\n",
      "/howo60_1696431778.2704687.pkl\n",
      "/howo60_1696431779.2710204.pkl\n",
      "/howo60_1696431780.2715638.pkl\n",
      "/howo60_1696431781.2704353.pkl\n",
      "/howo60_1696431782.2704365.pkl\n",
      "/howo60_1696431783.269757.pkl\n",
      "/howo60_1696431784.2722256.pkl\n",
      "/howo60_1696431785.2806754.pkl\n",
      "/howo60_1696431786.2738237.pkl\n",
      "/howo60_1696431787.2716534.pkl\n",
      "/howo60_1696431788.2718737.pkl\n",
      "/howo60_1696431789.2775016.pkl\n",
      "/howo60_1696431790.2728035.pkl\n",
      "/howo60_1696431791.2724066.pkl\n",
      "/howo60_1696431792.2703865.pkl\n",
      "/howo60_1696431793.270396.pkl\n",
      "/howo60_1696431794.270531.pkl\n",
      "/howo60_1696431795.2785692.pkl\n",
      "/howo60_1696431796.270533.pkl\n",
      "/howo60_1696431797.2708886.pkl\n",
      "/howo60_1696431798.2699487.pkl\n",
      "/howo60_1696431799.2722368.pkl\n",
      "/howo60_1696431800.2703655.pkl\n",
      "/howo60_1696431801.2703853.pkl\n",
      "/howo60_1696431802.2696786.pkl\n",
      "/howo60_1696431803.279471.pkl\n",
      "/howo60_1696431804.2725515.pkl\n",
      "/howo60_1696431805.2703786.pkl\n",
      "/howo60_1696431806.272484.pkl\n",
      "/howo60_1696431807.2723217.pkl\n",
      "/howo60_1696431808.2749906.pkl\n",
      "/howo60_1696431809.270505.pkl\n",
      "/howo60_1696431810.271358.pkl\n",
      "总共生成了198个数据\n"
     ]
    }
   ],
   "source": [
    "index = 3\n",
    "print(cur_files[index])\n",
    "load_seq_save_features(index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
